---
title: "Text mining code"
author: "Amy van der Ham"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Copy code from manuscript and run in separate file. This is the part that needs to be adjusted to develop the text mining with word vector embeddings. 

# Line 891 - 913 from manuscript
```{r}
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)

# makes it possible to call functions that are saved in separate R script
source("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/word_functions.R")
#source("circle2.R")

## Analysis 1:  Author keywords
# contains the dimensions of the recs dataframe 
# study1details <- read_yaml("study1_details.yml")

# note that dict from word_function.R is overwritten here
dict <- read_yaml("yaml_dict.txt")
# this dictionary was used later on to classify closely related terms -> If I am correct this what I want to do with word vector embedding instead. 

## Look at POS tags?
# reads file which contains the records into an object called recs
# this is were line 891 in manuscript file starts
recs <- read.csv("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/recs_final.csv")

# convert object into data table
recs <- as.data.table(recs)

# if recs is not an object of type data table 
# then code execution will be paused?
if(!is.data.table(recs)){
    browser()
  }

# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]

# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
  
## Extract individual words
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})

# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column. 
df <- merge_df(recs, df, "word")

# make sure that the values in the column word do not contain any capitals.   
df[, word := tolower(word)]
  
## Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")

# create an object with the number of unique documents (articles) in the data frame (df) and the number of unique (author key-) words in the data frame. 
number_docs_words <- c(docs = length(unique(df$doc)), words = 
                         length(unique(df$word)))

# save this information(# of articles and # of unique author keywords) in a yaml file 
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")

# check how many unique documents and words there are before excluding terms. 
length(unique(df$doc))
length(unique(df$word))

## Exclude words
# create object with the terms that should be excluded  
exclude_terms <- readLines("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/exclude_terms.txt")

# object with all the row numbers of author keywords that should be excluded from the data frame 
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))

# create new data frame that excludes all the row numbers that have an author keyword that should be excluded 
df <- df[!exclude_these, ]

# check how many unique documents and how many unique words there are after excluding non substantive words. 
length(unique(df$doc))
length(unique(df$word))

# NOTE after excluding the terms the corpus thus exists of 5030 documents with 7848 terms and not of 5031 terms with 8080 unique terms. 
```

# Also apply dictionary filter to see what happens. 
```{r}

# Categorize words
res_cat <- cat_words(df$word, dict, handle_dups = "all")
# Check coding issues
res_cat$dup  
head(res_cat$unmatched)

# Merge back with original data
df <- merge_df(df, res_cat$words, "word_coded")

# check the number of unique values in the column word_coded
length(unique(df$word_coded))
# -> 5292 (this is in line with what is stated in the paper)

# Check which value rows have in the column words and the column word_coded. Note that word_coded are the words that are included in the analysis. 
df[df$word == "mothers", c("word", "word_coded")]
df[df$word_coded == "parenting", c("word", "word_coded")]
df[df$word == "emotion socialization", c("word", "word_coded")]

# check words from figure 2
df[df$word == "emotion regulation", c("word", "word_coded")]
# emotion regulation can only be found in the column word and not in the column word_coded

df[df$word_coded == "SES", c("word", "word_coded")]
df[df$word_coded == "age", c("word", "word_coded")]
# these are mainly bigrams that belong to this word.

# check a word that is not in the dictionary
df[df$word_coded == "aboriginal", c("word", "word_coded")]
```

