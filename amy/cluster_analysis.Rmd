---
title: "Cluster analysis"
Author: "Amy van der Ham"
date: "10/8/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# load libraries
library(dplyr)
library(cluster)
library(ggplot2)
library(devtools)
```


```{r}
# load data frame with word vectors into object
df <- readRDS("featurematrix_asreview.RData")

# load data frame with column with selection of words to include in analysis
df_incltoken <- readRDS("include_token.RData")

df_incllemma <- readRDS("include_lemma.RData")

# create df in which only the words that we want to be included are kept
final_token <- subset(df, rownames(df) %in% df_incltoken$include_token)

final_lemma <- subset(df, rownames(df) %in% df_incllemma$include_lemma)

# check which words are in the included filter but are not in the feature matrix and are therefore lost (unwanted).
lost_token <- subset(df_incltoken, !(include_token %in% rownames(final_token)))
# 15343-14088 = 1255 observations

lost_lemma <- subset(df_incllemma, !(include_lemma %in% rownames(final_lemma)))
# 14195-11834 = 2361 observations
```
As expected least words are lost with the token_filter. Therefore for now I will keep working with final_token even though it might be that some words are in there more than needed and something like stemming or lemmatization should still be applied. But will first see if what happens if I conduct cluster analysis on this selection of words.

Note that I could also still bring the number of lost words down if I inspect them for example backgroundmindfulness. background can be included if I separate these two terms. ' and / & signs can be deleted or split on. But these are all minor things. So will first focus on cluster analysis. 

conclusionshealthy for example is a lost term however bith conclusions and healthy separatly are already inlcude in final_token, so the fact that conclusionshealthy is not included is no issue at all here. 

# STEMMING TRY-OUT
```{r}

```



