---
title: "K-means Clustering"
author: "Amy van der Ham"
date: "11/05/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Try out k-means clustering on the exsisting GloVe embedding on which the token filter is applied

```{r}
# load libraries
library(dplyr)
library(cluster)
library(ggplot2)
library(devtools)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
```

# set.seed prior to running the k-means clustering 
```{r}
set.seed(88)
```

# Load needed datafiles
```{r}
# load existing word embeddings
# load glove vectors into R
vectors_glove <- data.table::fread('glove.840B.300d.txt', data.table = F,  encoding = 'UTF-8', quote="") 

# rename the columns
colnames(vectors_glove) <- c('word',paste('dim',1:300,sep = '_'))

# load data frame with column with selection of words to include in analysis. 
df_incltoken <- readRDS("filter_token.RData")

# create df in which only the words that we want to be included are kept
token_embedding <- subset(vectors_glove, word %in% df_incltoken$filter_token)

# check number of unique words
length(unique((token_embedding$word)))
# 12743

# non-GloVe: check which words are in the token filter but are not in the feature matrix and are therefore lost (unwanted).
lost_tokens <- subset(df_incltoken, !(filter_token %in% token_embedding $word))
# 2117 words lost

length(unique((token_embedding$word))) + length(unique((lost_tokens$filter_token)))
# -> 14860. Which is equal to the line of code below. 
length(unique((df_incltoken$filter_token)))
```

# Make final GloVE embedding ready for analysis
```{r}
# convert first column, word, to row index
library(tidyverse)
glove_embedding <- token_embedding %>%
     remove_rownames() %>%
     column_to_rownames(var = 'word')

# convert dataframe to a matrix
glove_embedding <- as.matrix(glove_embedding)
str(glove_embedding)

# save the glove embedding to which the filter is applied so this can be easily loaded into other scripts
saveRDS(lemma_clean, "/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/glove_embedding.RData")
```

# Look at wich words are close to health
```{r}
library(text2vec)
# create function to find similar words based on cosine distance
find_similar_words <- function(word, embedding_matrix, n = 5) {
  similarities <- embedding_matrix[word, , drop = FALSE] %>%
    sim2(embedding_matrix, y = ., method = "cosine")
  
  similarities[, 1] %>% sort(decreasing = TRUE) %>% head(n)
}

find_similar_words("health",glove_embedding,25)
```

# Clustering analysis
- https://rstudio-pubs-static.s3.amazonaws.com/33876_1d7794d9a86647ca90c4f182df93f0e8.html

- https://www.r-bloggers.com/2013/09/clustering-search-keywords-using-k-means-clustering/

```{r}
# fit the k-means clustering with 100 clusters
k_means_fit <- kmeans(glove_embedding, 100, iter.max = 30, nstart = 25)

# obtain the centroids
k_means_fit$centers

# look at the size of the clusters
k_means_fit$size
min(k_means_fit$size)
max(k_means_fit$size)
# -> do not see a cluster with extremely low number of observations. Minimum is 23 and max is 287

# find the cluster to which each word belongs
k_means_fit$cluster

# The cost function in kmeans is the total sum of the squares
k_means_fit$totss

# results 
k_means_fit
# 26.7% of the total variance in the data set that is explained by the clustering

# Create data frame in which the merge cluster assignment back to rows/word. 
kw_with_cluster <- as.data.frame(cbind(row.names(glove_embedding), k_means_fit$cluster))
# add column names
names(kw_with_cluster) <- c("word", "kmeans100")

# save this data frame which contains a column with words and a column with to which cluster they belong
saveRDS(kw_with_cluster, "/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/clustering100.RData")

# make a df for the first 5 cluster results, quickly "eyeball" results
cluster1 <- subset(kw_with_cluster, subset=kmeans100 == 1)
cluster2 <- subset(kw_with_cluster, subset=kmeans100 == 2)
cluster3 <- subset(kw_with_cluster, subset=kmeans100 == 3)
cluster4 <- subset(kw_with_cluster, subset=kmeans100 == 4)
cluster5 <- subset(kw_with_cluster, subset=kmeans100 == 5)

# Mother 
# find out in which cluster the word mother is assigned
kw_with_cluster[kw_with_cluster$word == "mother", ]

# make a df of cluster 82
cluster82 <- subset(kw_with_cluster, subset = kmeans100 == 82)

# I did not setseeded the cluster analysis yet so want to compare the difference between the two clusters that contain the word mother. -> Can not rerun this code now that I have set.seeded the analysis but it is important to be aware that every time you run the analysis and do not set.seed, the clusters will be different. The 3 times I have now run the analysis the cluster containing mother had either 71, 70 or 86 observations. Final time the cluster had 112 observations.
diff_setseed <- subset(cluster6, !(word %in% cluster26$word))

# Health
# find out in which cluster the word health is assigned
kw_with_cluster[kw_with_cluster$word == "health", ]

# make a df of cluster 26
cluster26 <- subset(kw_with_cluster, subset=kmeans100 == 26)

# Environment
# find out in which cluster the word environment is assigned
kw_with_cluster[kw_with_cluster$word == "environment", ]

# make a df of cluster 28
cluster28 <- subset(kw_with_cluster, subset=kmeans100 == 28)

# Depression
# find out in which cluster the word depression is assigned so that I can check if all the forms of depression are in there. 
kw_with_cluster[kw_with_cluster$word == "depression", ]

# make a df of cluster 31
cluster31 <- subset(kw_with_cluster, subset=kmeans100 == 31)
# ->  If I look at the token_embedding dataframe and type depre in the filter within the word column I get the following words: nondepressed, antidepressant depressed, depression, depressive. It is suprising that some of these words fall in a different cluster.
kw_with_cluster[kw_with_cluster$word == "depressed", ]
kw_with_cluster[kw_with_cluster$word == "depressive", ]
kw_with_cluster[kw_with_cluster$word == "nondepressed", ]
kw_with_cluster[kw_with_cluster$word == "antidepressant", ]

# Kelly
# find out in which cluster the word Kelly is assigned so that I can check if all names are put together for example. 
kw_with_cluster[kw_with_cluster$word == "kelly", ]

# make a df of cluster 5
cluster5 <- subset(kw_with_cluster, subset=kmeans100 == 5)

# cortisol
# find out in which cluster the word cortisol is assigned so that I can check if all names are put together for example. 
kw_with_cluster[kw_with_cluster$word == "cortisol", ]

# make a df of cluster 100
cluster100 <- subset(kw_with_cluster, subset=kmeans100 == 100)

# empathy
# find out in which cluster the word empathy is assigned so that I can check if all names are put together for example. 
kw_with_cluster[kw_with_cluster$word == "empathy", ]

# make a df of cluster 30
cluster30 <- subset(kw_with_cluster, subset = kmeans100 == 30)
```

## Apply cluster analysis within a cluster (cluster 33) ##
-> heb het nu gerund met andere filter dus cluster nummers zijn nu anders dus moet dit even opnieuw doen. 
```{r}
# create new subset data frame
embedding_cluster33 <- subset(glove_embedding, rownames(glove_embedding) %in% cluster33$word)

# fit k-means
k_means_fit_cluster33 <- kmeans(embedding_cluster33, 3, iter.max = 30)

# look at the results
# obtain the centroids
k_means_fit_cluster33$centers

# look at the size of the clusters
k_means_fit_cluster33$size

# find the cluster to which each word belongs
k_means_fit_cluster33$cluster

# Create data frame in which the merge cluster assignment back to rows/word. 
token_within_clusters <- as.data.frame(cbind(row.names(embedding_cluster33), k_means_fit_cluster33$cluster))
# add column names
names(token_within_clusters) <- c("word", "kmeans3")

# make a df for the 3 cluster results
cluster33_1 <- subset(token_within_clusters, subset=kmeans3 == 1)
cluster33_2 <- subset(token_within_clusters, subset=kmeans3 == 2)
cluster33_3 <- subset(token_within_clusters, subset=kmeans3 == 3)

##  Determine the value of K 
library(factoextra)
# Elbow method
fviz_nbclust(embedding_cluster33, kmeans, method = "wss") + labs(subtitle = "Elbow method") # add subtitle

# geom_vline(xintercept = 4, linetype = 2) + # add line for better visualisation. I do not see a clear knee location in the plot. 

# Silhouette method
fviz_nbclust(embedding_cluster33, kmeans, method = "silhouette") +
  labs(subtitle = "Silhouette method")

# Gap statistic
fviz_nbclust(embedding_cluster33, kmeans,
  nstart = 25,
  method = "gap_stat",
  nboot = 500 # reduce it for lower computation time (but less precise results)
) +
  labs(subtitle = "Gap statistic method")


# try to determine number of cluster with NbClust package
library(NbClust)
nbclust_out <- NbClust(
  data = embedding_cluster33,
  distance = "euclidean",
  min.nc = 2, # minimum number of clusters
  max.nc = 10, # maximum number of clusters
  method = "kmeans", # one of: "ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"
  index = "silhouette"
)

nbclust_out

# create plot of results
factoextra::fviz_nbclust(nbclust_out) + theme_minimal() + ggtitle("NbClust's optimal number of clusters")

# Another package for determine number of clusters
library(ClusterR) 

Optimal_Clusters_KMeans(embedding_cluster33, 
              max_clusters = 15, 
              criterion = "distortion_fK",
              fK_threshold = 0.85, 
              num_init = 3, 
              max_iters = 50,
              initializer = "kmeans++",
              tol = 1e-04, 
              plot_clusters = TRUE,
              verbose = T, 
              tol_optimal_init = 0.3, 
              seed = 1)

# Run analysis with 10 clusters
km_res <- kmeans(embedding_cluster33, centers = 10, nstart = 20)

sil <- silhouette(km_res$cluster, dist(embedding_cluster33))
fviz_silhouette(sil)
# low average and negative values. 

# check cluster with highest silhouette index
resulting_clusters <- as.data.frame(cbind(row.names(embedding_cluster33), km_res$cluster))
# add column names
names(resulting_clusters) <- c("word", "kmeans10")

cluster5_highestsil <- subset(resulting_clusters, subset = kmeans10 == 5)

# visualize the k-means (2) clusters
fviz_cluster(k_means_fit_cluster33, data = embedding_cluster33,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
```

## CLUSTER ANALYSIS DETERMINING THE NUMBER OF CLUSTER FOR FULL DATASET##
# Determining the value of the parameter K for the glove_embedding matrix
```{r}
wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i, iter.max = 30)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")}

wssplot(glove_embedding, nc=150)
```

# K-means with K = 119
Based on the elbow plot above I see some sort of bend in the curve at a K value of about 119. So I will run K-means with K = 119 and look at the results. 

```{r}
# fit the k-means clustering with 133 clusters
k_means_fit119 <- kmeans(glove_embedding, 119, iter.max = 30, nstart = 25)

# obtain the centroids
k_means_fit119$centers

# look at the size of the clusters
k_means_fit119$size
min(k_means_fit119$size)
max(k_means_fit119$size)
# Examine clusters that have significantly fewer observations than other clusters. Clusters that have very few observations may contain outliers or unusual observations with unique characteristics. No clusters with extreme low number of observations. 

# find the cluster to which each word belongs
k_means_fit119$cluster

# The cost function in kmeans is the total sum of the squares
k_means_fit119$totss

# check results 
k_means_fit119
# -> 27.7% of the total variance in the data set that is explained by the clustering. 1% more than with 100 clusters

# Create data frame in which the merge cluster assignment back to rows/word. 
words_with_cluster119 <- as.data.frame(cbind(row.names(glove_embedding), k_means_fit119$cluster))

# add column names
names(words_with_cluster119) <- c("word", "kmeans119")

# save this data frame which contains a column with words and a column with to which cluster they belong
saveRDS(kw_with_cluster, "/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/clustering119.RData")

# check the largest cluster with 274 observations
cluster119_42 <- subset(words_with_cluster119, 
                   subset=kmeans119 == 42)
# cluster includes all kinds of abbreviations 

# Health
# find out in which cluster the word health is assigned
words_with_cluster119[words_with_cluster119$word == "health", ]

# make a df of cluster 107
cluster119_107 <- subset(words_with_cluster119, 
                    subset=kmeans119 == 107)

# Depression
# find out in which cluster the word depression is assigned
words_with_cluster119[words_with_cluster119$word == "depression", ]

# make a df of cluster 86
cluster119_86 <- subset(words_with_cluster119, 
                    subset=kmeans119 == 86)
# this cluster contains the word depression as well as depressive but not the word depressed 
```

# Using the package factoextra
https://statsandr.com/blog/clustering-analysis-k-means-and-hierarchical-clustering-by-hand-and-in-r/#silhouette-method
```{r}
# Elbow method
# toevoegen aan kmeans, iter.max = 30 en andere bins (stapjes 1-10, 10-20) op x as. 
fviz_nbclust(glove_embedding, kmeans, method = "wss", k.max = 150) + labs(subtitle = "Elbow method") # add subtitle

# geom_vline(xintercept = 4, linetype = 2) + # add line for better visualisation. I do not see a clear knee location in the plot. 

# Silhouette method
fviz_nbclust(glove_embedding, kmeans, method = "silhouette", k.max = 150) +
  labs(subtitle = "Silhouette method")


# Dit duurt heel lang
# Gap statistic
fviz_nbclust(glove_embedding, kmeans,
  nstart = 25,
  method = "gap_stat",
  nboot = 500 # reduce it for lower computation time (but less precise results)
) +
  labs(subtitle = "Gap statistic method")


# try to determine number of cluster with NbClust package
library(NbClust)
nbclust_out <- NbClust(
  data = glove_embedding,
  distance = "euclidean",
  min.nc = 2, # minimum number of clusters
  max.nc = 150, # maximum number of clusters
  method = "kmeans", # one of: "ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"
  index = "silhouette"
)
# duurt heel lang en krijg de converge warning weer. 

nbclust_out
```

# choosing the appropriate algoritm clValid package
```{r}
library(clValid)
intern <- clValid(glove_embedding, nClust = 2:125, 
              clMethods = c("hierarchical","kmeans"), validation = "internal")
y# Summary
summary(intern) %>% kable() %>% kable_styling()
```

