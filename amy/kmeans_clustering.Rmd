---
title: "K-means Clustering"
author: "Amy van der Ham"
date: "11/05/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Try out k-means clustering on the existing GloVe embedding on which the token filter is applied

```{r}
# load libraries
library(dplyr)
library(cluster)
library(ggplot2)
library(devtools)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
```

# set.seed prior to running the k-means clustering 
```{r}
set.seed(88)
```

# Load needed datafiles
```{r}
# load existing word embeddings
# load glove vectors into R
vectors_glove <- data.table::fread('glove.840B.300d.txt', data.table = F,  encoding = 'UTF-8', quote="") 

# rename the columns
colnames(vectors_glove) <- c('word',paste('dim',1:300,sep = '_'))

# load data frame with column with selection of words to include in analysis. 
df_incltoken <- readRDS("filter_token.RData")

# create df in which only the words that we want to be included are kept
token_embedding <- subset(vectors_glove, word %in% df_incltoken$filter_token)

# check number of unique words
length(unique((token_embedding$word)))
# 12743

# non-GloVe: check which words are in the token filter but are not in the feature matrix and are therefore lost (unwanted).
lost_tokens <- subset(df_incltoken, !(filter_token %in% token_embedding $word))
# 2117 words lost

length(unique((token_embedding$word))) + length(unique((lost_tokens$filter_token)))
# -> 14860. Which is equal to the line of code below. 
length(unique((df_incltoken$filter_token)))
```

# Make final GloVE embedding ready for analysis
```{r}
# convert the first column, word, to row index.
library(tidyverse)
glove_embedding <- token_embedding %>%
     remove_rownames() %>%
     column_to_rownames(var = 'word')

# convert dataframe to a matrix
glove_embedding <- as.matrix(glove_embedding)
str(glove_embedding)

# save the glove embedding to which the filter is applied so this can be easily loaded into other scripts
saveRDS(glove_embedding, "/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/glove_embedding.RData")
```

# Look at wich words are close to health
```{r}
library(text2vec)
# create function to find similar words based on cosine distance
find_similar_words <- function(word, embedding_matrix, n = 5) {
  similarities <- embedding_matrix[word, , drop = FALSE] %>%
    sim2(embedding_matrix, y = ., method = "cosine")
  
  similarities[, 1] %>% sort(decreasing = TRUE) %>% head(n)
}

# Run function on the word health and see the 25 closest words based on cosine similarity. 
find_similar_words("health",glove_embedding,25)
```

# Clustering analysis
- https://rstudio-pubs-static.s3.amazonaws.com/33876_1d7794d9a86647ca90c4f182df93f0e8.html

- https://www.r-bloggers.com/2013/09/clustering-search-keywords-using-k-means-clustering/

```{r}
# fit the k-means clustering with 100 clusters
k_means_fit <- kmeans(glove_embedding, 100, iter.max = 30, nstart = 25)

# obtain the centroids
k_means_fit$centers

# look at the size of the clusters
k_means_fit$size
min(k_means_fit$size)
max(k_means_fit$size)
# -> do not see a cluster with extremely low number of observations. Minimum is 23 and max is 287

# find the cluster to which each word belongs
k_means_fit$cluster

# The cost function in kmeans is the total sum of the squares
k_means_fit$totss

# results 
k_means_fit
# 26.7% of the total variance in the data set that is explained by the clustering

# Create data frame in which the cluster assignment is merged back to rows/word. 
words_with_cluster <- as.data.frame(cbind(row.names(glove_embedding), k_means_fit$cluster))
# add column names
names(words_with_cluster) <- c("word", "kmeans100")

# save this data frame which contains a column with words and a column with to which cluster they belong
saveRDS(words_with_cluster, "/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/clustering100.RData")

# make a df for the first 5 cluster results, quickly "eyeball" results
cluster1 <- subset(words_with_cluster, subset=kmeans100 == 1)
cluster2 <- subset(words_with_cluster, subset=kmeans100 == 2)
cluster3 <- subset(words_with_cluster, subset=kmeans100 == 3)
cluster4 <- subset(words_with_cluster, subset=kmeans100 == 4)
cluster5 <- subset(words_with_cluster, subset=kmeans100 == 5)

# Mother 
# find out in which cluster the word mother is assigned
words_with_cluster[words_with_cluster$word == "mother", ]

# make a df of cluster 82
cluster82 <- subset(words_with_cluster, subset = kmeans100 == 82)

# I did not setseeded the cluster analysis yet before so wanted to compare the difference between the two clusters that contain the word mother in the different runs of the same analysis. -> Can not rerun this code now that I have set.seeded the analysis but it is important to be aware that every time you run the analysis and do not set.seed, the clusters will be different. The 3 times I have now run the analysis the cluster containing mother had either 71, 70 or 86 observations. Final time this cluster had even 112 observations.
diff_setseed <- subset(cluster6, !(word %in% cluster26$word))

# Health
# find out in which cluster the word health is assigned
words_with_cluster[words_with_cluster$word == "health", ]

# make a df of cluster 26
cluster26 <- subset(words_with_cluster, subset=kmeans100 == 26)

# Environment
# find out in which cluster the word environment is assigned
words_with_cluster[words_with_cluster$word == "environment", ]

# make a df of cluster 28
cluster28 <- subset(words_with_cluster, subset=kmeans100 == 28)

# Depression
# find out to which cluster the word depression is assigned so that I can check if all the forms of depression are in there. 
words_with_cluster[words_with_cluster$word == "depression", ]

# make a df of cluster 31
cluster31 <- subset(words_with_cluster, subset=kmeans100 == 31)
# ->  If I look at the token_embedding dataframe and type depre in the filter within the word column I get the following words: nondepressed, antidepressant depressed, depression, depressive. It is surprising that some of these words fall in a different cluster. We wold expect at least depressed, depression and depressive to fall into the same cluster. 
words_with_cluster[words_with_cluster$word == "depressed", ]
words_with_cluster[words_with_cluster$word == "depressive", ]
words_with_cluster[words_with_cluster$word == "nondepressed", ]
words_with_cluster[words_with_cluster$word == "antidepressant", ]

# lets check the clusters that depressed and depressive belong to. 
# make a df of cluster 43 (depressed)
cluster43 <- subset(words_with_cluster, subset=kmeans100 == 43)

# make a df of cluster 36 (depressive)
cluster36 <- subset(words_with_cluster, subset=kmeans100 == 36)

# kelly
# find out in which cluster the word Kelly is assigned so that I can check if all names are put together for example. 
words_with_cluster[words_with_cluster$word == "kelly", ]
# -> kelly belongs to cluster 5 which is not unexpected because we already saw that cluster 5 contained names when we eyeballed the first 5 clusters earlier on. 

# cortisol
# find out in which cluster the word cortisol is assigned 
words_with_cluster[words_with_cluster$word == "cortisol", ]

# make a df of cluster 100
cluster100 <- subset(words_with_cluster, subset=kmeans100 == 100)

# empathy
# find out in which cluster the word empathy is assigned 
words_with_cluster[words_with_cluster$word == "empathy", ]

# make a df of cluster 30
cluster30 <- subset(words_with_cluster, subset = kmeans100 == 30)

# check the smallest cluster
cluster20 <- subset(words_with_cluster, subset = kmeans100 == 20)
# -> looks like this cluster represents games 

# check the largest cluster
cluster98 <- subset(words_with_cluster, subset = kmeans100 == 98)
# -> misspelled word emtional is in here, also the word afects and a lot of words starting with no(n)

# check another large cluster 
cluster17 <- subset(words_with_cluster, subset = kmeans100 == 17)
# -> these words are almost all abbreviations 

# check another large cluster 
cluster37 <- subset(words_with_cluster, subset = kmeans100 == 37)
# -> also some abbreviations and some words in other languages, dutch words (kinderen, psychologie, etc.) and french words (individuelles).
# -> would be interesting to do a cluster analysis on this to see if the dutch and french words will be put in separate clusters. 

# check cluster number 28 
cluster28 <- subset(words_with_cluster, subset = kmeans100 == 28)

# check cluster number 69
cluster69 <- subset(words_with_cluster, subset = kmeans100 == 69)
```

## Apply cluster analysis within a cluster (cluster 43) ##
```{r}
# create new subset data frame
embedding_cluster43 <- subset(glove_embedding, rownames(glove_embedding) %in% cluster43$word)

# fit k-means
k_means_fit3_cluster43 <- kmeans(embedding_cluster43, 3, iter.max = 30, nstart = 25)

# look at the results
# look at the size of the clusters
k_means_fit3_cluster43$size
k_means_fit3_cluster43

# Create data frame in which the merge cluster assignment back to rows/word. 
words_with_cluster43_3 <- as.data.frame(cbind(row.names(embedding_cluster43), k_means_fit3_cluster43$cluster))
# add column names
names(words_with_cluster43_3) <- c("word", "kmeans3")

# make a df for the 3 cluster results
cluster43_1 <- subset(words_with_cluster43_3, subset=kmeans3 == 1)
cluster43_2 <- subset(words_with_cluster43_3, subset=kmeans3 == 2)
cluster43_3 <- subset(words_with_cluster43_3, subset=kmeans3 == 3)

# visualize the k-means (with k = 3) clusters
library(factoextra)
fviz_cluster(k_means_fit3_cluster43, data = embedding_cluster43,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)

##  DETERMINING THE VALUE OF K
library(factoextra)
# Elbow method
fviz_nbclust(embedding_cluster43, kmeans, method = "wss") + geom_vline(xintercept = 7, linetype = 2) + # add line for better visualisation. 
  labs(subtitle = "Elbow method") # add subtitle
# -> not sure I interpret it correctly but would say the knee is at 6 or 7.   
 
# Silhouette method
fviz_nbclust(embedding_cluster43, kmeans, method = "silhouette") +
  labs(subtitle = "Silhouette method")
# -> suggests setting k to 4 or 9 clusters

# Note that I have set nboot really low for obtaining a quick result.  
# Gap statistic
fviz_nbclust(embedding_cluster43, kmeans,
  iter.max = 30,
  nstart = 25,
  method = "gap_stat",
  nboot = 5 # reduce it for lower computation time (but less precise results)
) +
  labs(subtitle = "Gap statistic method")
# -> suggests 8 clusters. 

# try to determine number of cluster with NbClust package
library(NbClust)
nbclust_out <- NbClust(
  data = embedding_cluster43,
  distance = "euclidean",
  min.nc = 2, # minimum number of clusters
  max.nc = 15, # maximum number of clusters
  method = "kmeans", # one of: "ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"
  index = "silhouette"
)

nbclust_out
# -> this gives a different result than the shiloutte plot. I wonder what the reason for this is. 

# Another package for determine number of clusters
library(ClusterR) 

Optimal_Clusters_KMeans(embedding_cluster43, 
              max_clusters = 15, 
              criterion = "distortion_fK",
              fK_threshold = 0.85, 
              num_init = 3, 
              max_iters = 50,
              initializer = "kmeans++",
              tol = 1e-04, 
              plot_clusters = TRUE,
              verbose = T, 
              tol_optimal_init = 0.3, 
              seed = 1)
# -> do not really know how to interpret this. 

Optimal_Clusters_KMeans(embedding_cluster43, max_clusters = 15, plot_clusters = T, criterion = 'silhouette')
# -> again gives different result based on silhouette. 

# RUN ANALYSIS WITH 8 CLUSTERS
# fit kmeans with 8 clusters
k_means_fit8_cluster43 <- kmeans(embedding_cluster43, 8, iter.max = 30, nstart = 25)

sil <- silhouette(k_means_fit8_cluster43$cluster, dist(embedding_cluster43))
fviz_silhouette(sil)
# -> the average silhouette width is low and there are quite some negative values. 

# # Create data frame in which the cluster assignment is merged back to rows/words.
words_with_cluster43_8 <- as.data.frame(cbind(row.names(embedding_cluster43), k_means_fit8_cluster43$cluster))
# add column names
names(words_with_cluster43_8) <- c("word", "kmeans8")

# cluster with highest silhouette value
cluster6_highestsil <- subset(words_with_cluster43_8, subset = kmeans8 == 6)

# visualize the k-means (with k = 8) clusters
fviz_cluster(k_means_fit8_cluster43, data = embedding_cluster43,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#3CB043", "#B2D3C2", "#354A21", "#EA3C53", "#8D021F", "#8F00FF", "#a88b32"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
```

## Apply cluster analysis within a cluster (cluster 37) ##
The resulting clusters do not really make sense to me. 
```{r}
# create new subset data frame
embedding_cluster37 <- subset(glove_embedding, rownames(glove_embedding) %in% cluster37$word)

# Silhouette method for determining k
fviz_nbclust(embedding_cluster37, kmeans, method = "silhouette") +
  labs(subtitle = "Silhouette method")
# -> suggests 2 or 5 as value for k

# fit k-means
k_means_fit5_cluster37 <- kmeans(embedding_cluster37, 5, iter.max = 30, nstart = 25)

# look at the size of the clusters
k_means_fit5_cluster37$size

# look at the results
k_means_fit5_cluster37 

# Create data frame in which the merge cluster assignment back to rows/word. 
words_with_cluster37_5 <- as.data.frame(cbind(row.names(embedding_cluster37), k_means_fit5_cluster37$cluster))
# add column names
names(words_with_cluster37_5 ) <- c("word", "kmeans5")

# make a df for the first 3 clusters
cluster37_1 <- subset(words_with_cluster37_5, subset=kmeans5 == 1)
cluster37_2 <- subset(words_with_cluster37_5, subset=kmeans5 == 2)
cluster37_3 <- subset(words_with_cluster37_5, subset=kmeans5 == 3)

# visualize the k-means (with k = 3) clusters
fviz_cluster(k_means_fit5_cluster37, data = embedding_cluster37,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07", "#8F00FF"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
```


##CLUSTER ANALYSIS DETERMINING THE NUMBER OF CLUSTER FOR FULL DATASET##
# Determining the value of the parameter K for the glove_embedding matrix
```{r}
wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i, iter.max = 30)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")}

wssplot(glove_embedding, nc=150)
```

# set seed again
```{r}
set.seed(88)
```

# Using the package factoextra
https://statsandr.com/blog/clustering-analysis-k-means-and-hierarchical-clustering-by-hand-and-in-r/#silhouette-method
```{r}
# Elbow method
fviz_nbclust(glove_embedding, kmeans(iter.max = 30, nstart = 25), method = "wss", k.max = 150) + labs(subtitle = "Elbow method") # add subtitle

# geom_vline(xintercept = 4, linetype = 2) + # add line for better visualisation. I do not see a clear knee location in the plot. 

# Silhouette method
fviz_nbclust(glove_embedding, kmeans(iter.max = 30, nstart = 25), method = "silhouette", k.max = 150) +
  labs(subtitle = "Silhouette method")

# Takes to long so did not run this. Could turn nboot down. 
# Gap statistic
fviz_nbclust(glove_embedding, kmeans,
  nstart = 25,
  method = "gap_stat",
  nboot = 500 # reduce it for lower computation time (but less precise results)
) +
  labs(subtitle = "Gap statistic method")


# try to determine number of cluster with NbClust package
library(NbClust)
nbclust_out <- NbClust(
  data = glove_embedding,
  distance = "euclidean",
  min.nc = 2, # minimum number of clusters
  max.nc = 150, # maximum number of clusters
  method = "kmeans", # one of: "ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"
  index = "silhouette"
)
# -> takes a really long time and gives converge warning. 
nbclust_out
```

# K-means with K = 119
Based on the elbow plot above I see some sort of bend in the curve at a K value of about 119. So I will run K-means with K = 119 and look at the results. 

*Note* Not sure if I have interpreted the plot correctly. Also you can see a knee at 45 and 100 for k as well I think. 

```{r}
# fit the k-means clustering with 119 clusters
k_means_fit119 <- kmeans(glove_embedding, 119, iter.max = 30, nstart = 25)

# look at the size of the clusters
k_means_fit119$size
min(k_means_fit119$size)
max(k_means_fit119$size)
# Examine clusters that have significantly fewer observations than other clusters. Clusters that have very few observations may contain outliers or unusual observations with unique characteristics. No clusters with extreme low number of observations. Minimum is 34 and maximum is 246

# The cost function in kmeans is the total sum of the squares
k_means_fit119$totss

# check results 
k_means_fit119
# -> 27.8% of the total variance in the data set that is explained by the clustering. 1% more than with 100 clusters

# Create data frame in which the merge cluster assignment back to rows/word. 
words_with_cluster119 <- as.data.frame(cbind(row.names(glove_embedding), k_means_fit119$cluster))

# add column names
names(words_with_cluster119) <- c("word", "kmeans119")

# save this data frame which contains a column with words and a column with to which cluster they belong
saveRDS(words_with_cluster119, "/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/clustering119.RData")

# check the largest cluster with 246 observations
cluster119_55 <- subset(words_with_cluster119, 
                   subset=kmeans119 == 55)
# -> cluster includes all sorts of abbreviations 

# check the smallest cluster with 34 observations
cluster119_32 <- subset(words_with_cluster119, 
                   subset=kmeans119 == 32)
# -> contains single letters and different units of measurement. 

# Health
# find out in which cluster the word health is assigned
words_with_cluster119[words_with_cluster119$word == "health", ]

# make a df of cluster 85
cluster119_85 <- subset(words_with_cluster119, 
                    subset=kmeans119 == 85)

# Depression
# find out in which cluster the word depression is assigned
words_with_cluster119[words_with_cluster119$word == "depression", ]

# make a df of cluster 10
cluster119_10 <- subset(words_with_cluster119, 
                    subset=kmeans119 == 10)
# -> this cluster also contains the word depressive but not the word depressed. 

words_with_cluster119[words_with_cluster119$word == "depressed", ]
words_with_cluster119[words_with_cluster119$word == "nondepressed", ]
words_with_cluster119[words_with_cluster119$word == "antidepressant", ]
```
