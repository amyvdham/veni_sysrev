---
title: "Try - out K-means"
author: "Amy van der Ham"
date: "11/04/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Try out k-means clustering on the embeddings on which the pre-processing lemma filter is applied

```{r}
# load libraries
library(dplyr)
library(cluster)
library(ggplot2)
library(devtools)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
```

# set.seed prior to running the k-means clustering 
```{r}
set.seed(88)
```

# Load needed datafiles
```{r}
# load existing word embeddings
# load glove vectors into R
vectors_glove <- data.table::fread('glove.840B.300d.txt', data.table = F,  encoding = 'UTF-8', quote="") 

# rename the columns
colnames(vectors_glove) <- c('word',paste('dim',1:300,sep = '_'))

# load data frame with column with selection of words to include in analysis. For now I will only 
df_incllemma <- readRDS("include_lemma.RData")

# create df in which only the words that we want to be included are kept
lemma_embedding <- subset(vectors_glove, word %in% df_incllemma$include_lemma)

# check number of unique words
length(unique((lemma_embedding$word)))

# non-GloVe: check which words are in the included filter but are not in the feature matrix and are therefore lost (unwanted).
lost_lemma <- subset(df_incllemma, !(include_lemma %in% lemma_embedding $word))
# 2768 words lost

length(unique((lemma_embedding$word))) + length(unique((lost_lemma$include_lemma)))
# ->  14195: dit is gelijk aan:
length(unique((df_incllemma$include_lemma)))
```

# Make final GloVE embedding ready for analysis
```{r}
# convert first column, word, to row index
library(tidyverse)
glove_embedding <- lemma_embedding %>%
     remove_rownames() %>%
     column_to_rownames(var = 'word')

# convert dataframe to a matrix
glove_embedding <- as.matrix(glove_embedding)
str(glove_embedding)
```

# Look at wich words are close to health
```{r}
library(text2vec)
find_similar_words <- function(word, embedding_matrix, n = 5) {
  similarities <- embedding_matrix[word, , drop = FALSE] %>%
    sim2(embedding_matrix, y = ., method = "cosine")
  
  similarities[, 1] %>% sort(decreasing = TRUE) %>% head(n)
}

find_similar_words("health",glove_embedding,25)
```

# Clustering analysis
- https://rstudio-pubs-static.s3.amazonaws.com/33876_1d7794d9a86647ca90c4f182df93f0e8.html

- https://www.r-bloggers.com/2013/09/clustering-search-keywords-using-k-means-clustering/

```{r}
# fit the k-means clustering with 100 clusters
k_means_fit <- kmeans(glove_embedding, 100, iter.max = 30, nstart = 25)

# obtain the centroids
k_means_fit$centers

# look at the size of the clusters
k_means_fit$size
min(k_means_fit$size)
max(k_means_fit$size)
# -> do not see a cluster with extremely low number of observations. Minimum is 27 and max is 381

# find the cluster to which each word belongs
k_means_fit$cluster

# The cost function in kmeans is the total sum of the squares
k_means_fit$totss

# results 
k_means_fit
# 26.8 % of the total variance in the data set that is explained by the clustering

# Create data frame in which the merge cluster assignment back to rows/word. 
kw_with_cluster <- as.data.frame(cbind(row.names(glove_embedding), k_means_fit$cluster))
# add column names
names(kw_with_cluster) <- c("word", "kmeans100")

# make a df for the first 5 cluster results, quickly "eyeball" results
cluster1 <- subset(kw_with_cluster, subset=kmeans100 == 1)
cluster2 <- subset(kw_with_cluster, subset=kmeans100 == 2)
cluster3 <- subset(kw_with_cluster, subset=kmeans100 == 3)
cluster4 <- subset(kw_with_cluster, subset=kmeans100 == 4)
cluster5 <- subset(kw_with_cluster, subset=kmeans100 == 5)

# Mother 
# find out in which cluster the word mother is assigned
kw_with_cluster[kw_with_cluster$word == "mother", ]

# make a df of cluster 25
cluster25 <- subset(kw_with_cluster, subset = kmeans100 == 25)

# I did not setseeded the cluster analysis yet so want to compare the difference between the two clusters that contain the word mother. -> Can not rerun this code now that I have set.seeded the analysis but it is important to be aware that every time you run the analysis and do not set.seed, the clusters will be different. The 3 times I have now run the analysis the cluster containing mother had either 71, 70 or 86 observations. 
diff_setseed <- subset(cluster6, !(word %in% cluster26$word))

# Health
# find out in which cluster the word health is assigned
kw_with_cluster[kw_with_cluster$word == "health", ]

# make a df of cluster 74
cluster74 <- subset(kw_with_cluster, subset=kmeans100 == 74)

# Environment
# find out in which cluster the word environment is assigned
kw_with_cluster[kw_with_cluster$word == "environment", ]

# make a df of cluster 66
cluster66 <- subset(kw_with_cluster, subset=kmeans100 == 66)

# Depression
# find out in which cluster the word depression is assigned so that I can check if all the forms of depression are in there. 
kw_with_cluster[kw_with_cluster$word == "depression", ]

# make a df of cluster 8
cluster8 <- subset(kw_with_cluster, subset=kmeans100 == 8)
# ->  depressed, depression and depressive are in this cluster. If I look at the lemma_embedding dataframe and type depre in the filter within the word column I get the following words: nondepressed, antidepressant depressed, depression, depressive. It is not completely surprising that these other two words fall in a different cluster
kw_with_cluster[kw_with_cluster$word == "depressed", ]
kw_with_cluster[kw_with_cluster$word == "depressive", ]
kw_with_cluster[kw_with_cluster$word == "nondepressed", ]
kw_with_cluster[kw_with_cluster$word == "antidepressant", ]

# Kelly
# find out in which cluster the word Kelly is assigned so that I can check if all names are put together for example. 
kw_with_cluster[kw_with_cluster$word == "kelly", ]

# make a df of cluster 87
cluster87 <- subset(kw_with_cluster, subset=kmeans100 == 87)

# cortisol
# find out in which cluster the word cortisol is assigned so that I can check if all names are put together for example. 
kw_with_cluster[kw_with_cluster$word == "cortisol", ]

# make a df of cluster 56
cluster56 <- subset(kw_with_cluster, subset=kmeans100 == 56)

# empathy
# find out in which cluster the word empathy is assigned so that I can check if all names are put together for example. 
kw_with_cluster[kw_with_cluster$word == "empathy", ]

# make a df of cluster 71
cluster71 <- subset(kw_with_cluster, subset = kmeans100 == 71)
```

## Apply cluster analysis within a cluster (cluster 33) ##
-> heb het nu gerund met nstart = 25 dus cluster nummers zijn nu anders dus moet dit even opnieuw doen. 
```{r}
# create new subset data frame
embedding_cluster33 <- subset(glove_embedding, rownames(glove_embedding) %in% cluster33$word)

# fit k-means
k_means_fit_cluster33 <- kmeans(embedding_cluster33, 3, iter.max = 30)

# look at the results
# obtain the centroids
k_means_fit_cluster33$centers

# look at the size of the clusters
k_means_fit_cluster33$size

# find the cluster to which each word belongs
k_means_fit_cluster33$cluster

# Create data frame in which the merge cluster assignment back to rows/word. 
token_within_clusters <- as.data.frame(cbind(row.names(embedding_cluster33), k_means_fit_cluster33$cluster))
# add column names
names(token_within_clusters) <- c("word", "kmeans3")

# make a df for the 3 cluster results
cluster33_1 <- subset(token_within_clusters, subset=kmeans3 == 1)
cluster33_2 <- subset(token_within_clusters, subset=kmeans3 == 2)
cluster33_3 <- subset(token_within_clusters, subset=kmeans3 == 3)

##  Determine the value of K 
library(factoextra)
# Elbow method
fviz_nbclust(embedding_cluster33, kmeans, method = "wss") + labs(subtitle = "Elbow method") # add subtitle

# geom_vline(xintercept = 4, linetype = 2) + # add line for better visualisation. I do not see a clear knee location in the plot. 

# Silhouette method
fviz_nbclust(embedding_cluster33, kmeans, method = "silhouette") +
  labs(subtitle = "Silhouette method")

# Gap statistic
fviz_nbclust(embedding_cluster33, kmeans,
  nstart = 25,
  method = "gap_stat",
  nboot = 500 # reduce it for lower computation time (but less precise results)
) +
  labs(subtitle = "Gap statistic method")


# try to determine number of cluster with NbClust package
library(NbClust)
nbclust_out <- NbClust(
  data = embedding_cluster33,
  distance = "euclidean",
  min.nc = 2, # minimum number of clusters
  max.nc = 10, # maximum number of clusters
  method = "kmeans", # one of: "ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"
  index = "silhouette"
)

nbclust_out

# create plot of results
factoextra::fviz_nbclust(nbclust_out) + theme_minimal() + ggtitle("NbClust's optimal number of clusters")

# Another package for determine number of clusters
library(ClusterR) 

Optimal_Clusters_KMeans(embedding_cluster33, 
              max_clusters = 15, 
              criterion = "distortion_fK",
              fK_threshold = 0.85, 
              num_init = 3, 
              max_iters = 50,
              initializer = "kmeans++",
              tol = 1e-04, 
              plot_clusters = TRUE,
              verbose = T, 
              tol_optimal_init = 0.3, 
              seed = 1)

# Run analysis with 10 clusters
km_res <- kmeans(embedding_cluster33, centers = 10, nstart = 20)

sil <- silhouette(km_res$cluster, dist(embedding_cluster33))
fviz_silhouette(sil)
# low average and negative values. 

# check cluster with highest silhouette index
resulting_clusters <- as.data.frame(cbind(row.names(embedding_cluster33), km_res$cluster))
# add column names
names(resulting_clusters) <- c("word", "kmeans10")

cluster5_highestsil <- subset(resulting_clusters, subset = kmeans10 == 5)

# visualize the k-means (2) clusters
fviz_cluster(k_means_fit_cluster33, data = embedding_cluster33,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
```

## CLUSTER ANALYSIS DETERMINING THE NUMBER OF CLUSTER FOR FULL DATASET##
# Determining the value of the parameter K for the glove_embedding matrix
This gives warning about the number of iterations being set to 10 is not enough to converge. So will need to adjust this. Next to this the resulting plot does not give a clear elbow point. 
```{r}
wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i, iter.max = 30)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")}

wssplot(glove_embedding, nc=150)
```

# K-means with K = 133
Based on the elbow plot above I see some sort of bend in the curve at a K value of about 133. So I will run K-means with K = 133 and look at the results. 

```{r}
# fit the k-means clustering with 133 clusters
k_means_fit133 <- kmeans(glove_embedding, 133, iter.max = 30, nstart = 25)

# obtain the centroids
k_means_fit133$centers

# look at the size of the clusters
k_means_fit133$size
min(k_means_fit133$size)
max(k_means_fit133$size)
# Examine clusters that have significantly fewer observations than other clusters. Clusters that have very few observations may contain outliers or unusual observations with unique characteristics. Pay attention to cluster 32 (size = 12).

# find the cluster to which each word belongs
k_means_fit133$cluster

# The cost function in kmeans is the total sum of the squares
k_means_fit133$totss

# check results 
k_means_fit133
# -> 28.4% of the total variance in the data set that is explained by the clustering. 1.6% more than with 100 clusters

# Create data frame in which the merge cluster assignment back to rows/word. 
words_with_cluster133 <- as.data.frame(cbind(row.names(glove_embedding), k_means_fit133$cluster))

# add column names
names(words_with_cluster133) <- c("word", "kmeans133")

# check the cluster with only 12 observations
cluster133_32 <- subset(words_with_cluster133, 
                   subset=kmeans133 == 32)
# looks like it includes Chinese words/places? 

# check the largest cluster with 216 observations
cluster133_76 <- subset(words_with_cluster133, 
                   subset=kmeans133 == 76)

# Health
# find out in which cluster the word health is assigned
words_with_cluster133[words_with_cluster133$word == "health", ]

# make a df of cluster 50
cluster133_50 <- subset(words_with_cluster133, 
                    subset=kmeans133 == 50)

# Depression
# find out in which cluster the word depression is assigned
words_with_cluster133[words_with_cluster133$word == "depression", ]

# make a df of cluster 108
cluster133_108 <- subset(words_with_cluster133, 
                    subset=kmeans133 == 108)
# now it only contains depression and not the other forms of the words. 
```

# Using the package factoextra
https://statsandr.com/blog/clustering-analysis-k-means-and-hierarchical-clustering-by-hand-and-in-r/#silhouette-method
```{r}
# Elbow method
# toevoegen aan kmeans, iter.max = 30 en andere bins (stapjes 1-10, 10-20) op x as. 
fviz_nbclust(glove_embedding, kmeans, method = "wss", k.max = 150) + labs(subtitle = "Elbow method") # add subtitle

# geom_vline(xintercept = 4, linetype = 2) + # add line for better visualisation. I do not see a clear knee location in the plot. 

# Silhouette method
fviz_nbclust(glove_embedding, kmeans, method = "silhouette", k.max = 150) +
  labs(subtitle = "Silhouette method")


# Dit duurt heel lang
# Gap statistic
fviz_nbclust(glove_embedding, kmeans,
  nstart = 25,
  method = "gap_stat",
  nboot = 500 # reduce it for lower computation time (but less precise results)
) +
  labs(subtitle = "Gap statistic method")


# try to determine number of cluster with NbClust package
library(NbClust)
nbclust_out <- NbClust(
  data = glove_embedding,
  distance = "euclidean",
  min.nc = 2, # minimum number of clusters
  max.nc = 150, # maximum number of clusters
  method = "kmeans", # one of: "ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"
  index = "silhouette"
)
# duurt heel lang en krijg de converge warning weer. 

nbclust_out
```

# choosing the appropriate algoritm clValid package
```{r}
library(clValid)
intern <- clValid(glove_embedding, nClust = 2:125, 
              clMethods = c("hierarchical","kmeans"), validation = "internal")
y# Summary
summary(intern) %>% kable() %>% kable_styling()
```

