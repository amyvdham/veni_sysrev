# CLUSTER ANALYSIS WITHIN CLUSTER
# create new subset data frame
embedding_cluster18 <- subset(glove_embedding, rownames(glove_embedding) %in% cluster125_18$word)
# fit k-means
kmeans_fit3_cluster18 <- kmeans(embedding_cluster18, 3, iter.max = 30, nstart = 25)
# visualize the k-means (with k = 3) clusters
fviz_cluster(kmeans_fit3_cluster18, data = embedding_cluster18,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
# CLUSTER ANALYSIS WITHIN CLUSTER
# create new subset data frame
embedding_cluster21 <- subset(glove_embedding, rownames(glove_embedding) %in% cluster125_21$word)
# fit k-means
kmeans_fit3_cluster21 <- kmeans(embedding_cluster21, 3, iter.max = 30, nstart = 25)
# visualize the k-means (with k = 3) clusters
fviz_cluster(kmeans_fit3_cluster21, data = embedding_cluster18,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
# visualize the k-means (with k = 3) clusters
fviz_cluster(kmeans_fit3_cluster21, data = embedding_cluster21,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
# look at the results
# Create data frame in which the merge cluster assignment back to rows/word.
words_with_cluster21_3 <- as.data.frame(cbind(row.names(embedding_cluster21), kmeans_fit3_cluster21$cluster))
# add column names
names(words_with_cluster21_3) <- c("word", "kmeans3")
# make a df for the 3 cluster results
cluster21_1 <- subset(words_with_cluster46_3, subset=kmeans3 == 1)
cluster21_2 <- subset(words_with_cluster46_3, subset=kmeans3 == 2)
cluster21_3 <- subset(words_with_cluster46_3, subset=kmeans3 == 3)
# make a df for the 3 cluster results
cluster21_1 <- subset(words_with_cluster21_3, subset=kmeans3 == 1)
cluster21_2 <- subset(words_with_cluster21_3, subset=kmeans3 == 2)
cluster21_3 <- subset(words_with_cluster21_3, subset=kmeans3 == 3)
View(cluster21_1)
View(cluster21_2)
View(cluster21_3)
View(cluster125_18)
View(cluster125_18)
cluster125_37 <- subset(words_with_cluster125, subset=kmeans125 == 37)
View(cluster125_37)
cluster125_38 <- subset(words_with_cluster125, subset=kmeans125 == 38)
View(cluster125_38)
cluster125_36 <- subset(words_with_cluster125, subset=kmeans125 == 36)
View(cluster125_36)
cluster125_31 <- subset(words_with_cluster125, subset=kmeans125 == 31)
View(cluster125_31)
cluster125_32 <- subset(words_with_cluster125, subset=kmeans125 == 32)
View(cluster125_32)
cluster125_31 <- subset(words_with_cluster125, subset=kmeans125 == 31)
View(cluster125_31)
cluster125_46 <- subset(words_with_cluster125, subset=kmeans125 == 46)
View(cluster125_46)
cluster125_45 <- subset(words_with_cluster125, subset=kmeans125 == 45)
View(cluster125_45)
cluster125_113 <- subset(words_with_cluster125, subset=kmeans125 == 113)
View(cluster125_113)
cluster125_114 <- subset(words_with_cluster125, subset=kmeans125 == 114)
View(cluster125_114)
cluster125_115 <- subset(words_with_cluster125, subset=kmeans125 == 115)
View(cluster125_115)
cluster125_120 <- subset(words_with_cluster125, subset=kmeans125 == 12o)
cluster125_120 <- subset(words_with_cluster125, subset=kmeans125 == 120)
View(cluster125_120)
# create new subset data frame
embedding_cluster120 <- subset(glove_embedding, rownames(glove_embedding) %in% cluster125_120$word)
# fit k-means
kmeans_fit3_cluster120 <- kmeans(embedding_cluster120, 3, iter.max = 30, nstart = 25)
fviz_cluster(kmeans_fit3_cluster120, data = embedding_cluster120,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
# fit k-means
kmeans_fit3_cluster21 <- kmeans(embedding_cluster124, 3, iter.max = 30, nstart = 25)
# look at the results
# Create data frame in which the merge cluster assignment back to rows/word.
words_with_cluster124_3 <- as.data.frame(cbind(row.names(embedding_cluster124), kmeans_fit3_cluster124$cluster))
# fit k-means
kmeans_fit3_cluster124 <- kmeans(embedding_cluster124, 3, iter.max = 30, nstart = 25)
# look at the results
# Create data frame in which the merge cluster assignment back to rows/word.
words_with_cluster124_3 <- as.data.frame(cbind(row.names(embedding_cluster124), kmeans_fit3_cluster124$cluster))
# add column names
names(words_with_cluster124_3) <- c("word", "kmeans3")
# visualize the k-means (with k = 3) clusters
fviz_cluster(kmeans_fit3_cluster124, data = embedding_cluster124,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
View(cluster125_21)
tsne_clst_112_w2v <- Rtsne(embedding_cluster112_w2v, dims = 2, perplexity = 30, verbose=TRUE, max_iter = 500, pca = TRUE)
tsne_clst_112_w2v <- Rtsne(embedding_cluster112_w2v, dims = 2, perplexity = 40, verbose=TRUE, max_iter = 500, pca = TRUE)
tsne_clst_112_w2v <- Rtsne(embedding_cluster112_w2v, dims = 2, perplexity = 45, verbose=TRUE, max_iter = 500, pca = TRUE)
tsne_clst_112_w2v <- Rtsne(embedding_cluster112_w2v, dims = 2, perplexity = 50, verbose=TRUE, max_iter = 500, pca = TRUE)
tsne_clst_112_w2v <- Rtsne(embedding_cluster112_w2v, dims = 2, perplexity = 55, verbose=TRUE, max_iter = 500, pca = TRUE)
tsne_clst_112_w2v <- Rtsne(embedding_cluster112_w2v, dims = 2, perplexity = 65, verbose=TRUE, max_iter = 500, pca = TRUE)
tsne_clst_112_w2v <- Rtsne(embedding_cluster112_w2v, dims = 2, perplexity = 80, verbose=TRUE, max_iter = 500, pca = TRUE)
tsne_clst_112_w2v <- Rtsne(embedding_cluster112_w2v, dims = 2, perplexity = 75, verbose=TRUE, max_iter = 500, pca = TRUE)
plot_df <- data.frame(tsne_clst_112_w2v $Y) %>%
mutate(
word = embedding_cluster112_w2v_plot$word,
)
p <- ggplot(plot_df, aes(X1, X2)) +
geom_text(aes(X1, X2, label = word), size = 3) +
xlab("") + ylab("") +
ggtitle("2-dimensional t-SNE Mapping of Word Vectors Belonging to Cluster 112 - W2V") +
theme(legend.position = "none") +
theme_minimal()
p
tsne_clst_112_w2v <- Rtsne(embedding_cluster112_w2v, dims = 2, perplexity = 78, verbose=TRUE, max_iter = 500, pca = TRUE)
tsne_clst_112_w2v <- Rtsne(embedding_cluster112_w2v, dims = 2, perplexity = 77, verbose=TRUE, max_iter = 500, pca = TRUE)
plot_df <- data.frame(tsne_clst_112_w2v $Y) %>%
mutate(
word = embedding_cluster112_w2v_plot$word,
)
p <- ggplot(plot_df, aes(X1, X2)) +
geom_text(aes(X1, X2, label = word), size = 3) +
xlab("") + ylab("") +
ggtitle("2-dimensional t-SNE Mapping of Word Vectors Belonging to Cluster 112 - W2V") +
theme(legend.position = "none") +
theme_minimal()
p
p <- ggplot(plot_df, aes(X1, X2)) +
geom_text(aes(X1, X2, label = word), size = 3) +
xlab("") + ylab("") +
ggtitle("2-dimensional t-SNE Mapping of Word Vectors Belonging to Cluster 112 - W2V") +
theme(legend.position = "none") +
theme_minimal() +
xlim(-5, 5)
p
p <- ggplot(plot_df, aes(X1, X2)) +
geom_text(aes(X1, X2, label = word), size = 3) +
xlab("") + ylab("") +
ggtitle("2-dimensional t-SNE Mapping of Word Vectors Belonging to Cluster 112 - W2V") +
theme(legend.position = "none") +
theme_minimal() +
xlim(-4, 3)
p
p <- ggplot(plot_df, aes(X1, X2)) +
geom_text(aes(X1, X2, label = word), size = 3) +
xlab("") + ylab("") +
ggtitle("2-dimensional t-SNE Mapping of Word Vectors Belonging to Cluster 112 - W2V") +
theme(legend.position = "none") +
theme_minimal() +
xlim(-3.8, 3.5)
p
View(cluster125_w2v_112)
# CLUSTER ANALYSIS WITHIN CLUSTER
# fit k-means
kmeans_fit3_cluster112_w2v <- kmeans(embedding_cluster112_w2v, 3, iter.max = 30, nstart = 25)
# look at the results
# Create data frame in which the merge cluster assignment back to rows/word.
words_with_cluster112_w2v_3 <- as.data.frame(cbind(row.names(embedding_cluster112_w2v), kmeans_fit3_cluster112_w2v$cluster))
# add column names
names(words_with_cluster112_w2v_3) <- c("word", "kmeans3")
# visualize the k-means (with k = 3) clusters
fviz_cluster(kmeans_fit3_cluster112_w2v, data = embedding_cluster112_w2v,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
View(cluster125_w2v_61)
fviz_silhouette(sil)
View(cluster125_w2v_112)
# load libraries
library(dplyr)
library(cluster)
library(ggplot2)
library(devtools)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(factoextra)
set.seed(88)
# load glove word embedding file
glove_embedding <- readRDS("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/try_outs/glove_embedding_final.RData")
# load w2v bigrams word embedding file
w2v_bigrams_embedding <- readRDS("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/w2v_bigrams_embedding.RData")
library(text2vec)
# create function to find similar words based on cosine distance
find_similar_words <- function(word, embedding_matrix, n = 5) {
similarities <- embedding_matrix[word, , drop = FALSE] %>%
sim2(embedding_matrix, y = ., method = "cosine")
similarities[, 1] %>% sort(decreasing = TRUE) %>% head(n)
}
# check if socio-emotional and socioemotional are similar words in the glove bigrams embedding
find_similar_words("socio-emotional",glove_bigrams_embedding,25)
# load glove bigrams word embedding file
glove_bigrams_embedding <-  readRDS("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/try_outs/glove_embedding_bigrams.RData")
# check if socio-emotional and socioemotional are similar words in the glove bigrams embedding
find_similar_words("socio-emotional",glove_bigrams_embedding,25)
find_similar_words("socioemotional",glove_bigrams_embedding,25)
set.seed(88)
# fit the k-means clustering with 125 clusters
kmeans_fit125 <- kmeans(glove_embedding, 125, iter.max = 30, nstart = 25)
# fit the k-means clustering with 125 clusters
kmeans_fit125 <- kmeans(glove_embedding, 125, iter.max = 30, nstart = 25)
# results
kmeans_fit125
# obtain the centroids
kmeans_fit125$centers
# look at the size of the clusters
kmeans_fit125$size
min(kmeans_fit125$size)
max(kmeans_fit125$size)
# CHECK CLUSTERS
# Create data frame in which the cluster assignment is merged back to rows/word.
words_with_cluster125 <- as.data.frame(cbind(row.names(glove_embedding), kmeans_fit125$cluster))
# add column names
names(words_with_cluster125) <- c("word", "kmeans125")
# Check cluster with highest silhouette average
cluster125_hghsil <- subset(words_with_cluster125, subset=kmeans125 == 47)
View(cluster125_hghsil)
# load libraries
library(dplyr)
library(cluster)
library(ggplot2)
library(devtools)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(factoextra)
set.seed(88)
# load glove word embedding file
glove_embedding <- readRDS("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/try_outs/glove_embedding_final.RData")
# load w2v word embedding file
w2v_embedding <- readRDS("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/w2v_embedding.RData")
set.seed(88)
# fit the k-means clustering with 125 clusters
kmeans_fit125 <- kmeans(glove_embedding, 125, iter.max = 30, nstart = 25)
# results
kmeans_fit125
# look at the size of the clusters
kmeans_fit125$size
min(kmeans_fit125$size)
max(kmeans_fit125$size)
# silhouette width
sil <- silhouette(kmeans_fit125$cluster, dist(glove_embedding))
fviz_silhouette(sil)
# CHECK CLUSTERS
# Create data frame in which the cluster assignment is merged back to rows/word.
words_with_cluster125 <- as.data.frame(cbind(row.names(glove_embedding), kmeans_fit125$cluster))
# add column names
names(words_with_cluster125) <- c("word", "kmeans125")
# Check cluster with highest silhouette average
cluster125_hghsil <- subset(words_with_cluster125, subset=kmeans125 == 47)
View(cluster125_hghsil)
# Check smallest cluster
cluster125_97 <- subset(words_with_cluster125, subset=kmeans125 == 97)
View(cluster125_97)
# Mother
# find out in which cluster the word mother is assigned
words_with_cluster125[words_with_cluster125$word == "mother", ]
cluster125_21 <- subset(words_with_cluster125, subset=kmeans125 == 21)
View(cluster125_97)
View(cluster125_21)
# check a cluster with a low average silhouette width
cluster125_lowsil2 <- subset(words_with_cluster125, subset=kmeans125 == 124)
View(cluster125_lowsil2)
# CLUSTER ANALYSIS WITHIN CLUSTER
# create new subset data frame
embedding_cluster21 <- subset(glove_embedding, rownames(glove_embedding) %in% cluster125_21$word)
# fit k-means
kmeans_fit3_cluster21 <- kmeans(embedding_cluster21, 3, iter.max = 30, nstart = 25)
# look at the results
# Create data frame in which the merge cluster assignment back to rows/word.
words_with_cluster21_3 <- as.data.frame(cbind(row.names(embedding_cluster21), kmeans_fit3_cluster21$cluster))
# add column names
names(words_with_cluster21_3) <- c("word", "kmeans3")
# make a df for the 3 cluster results
cluster21_1 <- subset(words_with_cluster21_3, subset=kmeans3 == 1)
cluster21_2 <- subset(words_with_cluster21_3, subset=kmeans3 == 2)
cluster21_3 <- subset(words_with_cluster21_3, subset=kmeans3 == 3)
# visualize the k-means (with k = 3) clusters
fviz_cluster(kmeans_fit3_cluster21, data = embedding_cluster21,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
# CLUSTER ANALYSIS W2V BIGRAMS
# fit the k-means clustering with 125 clusters on w2v bigrams embedding.
kmeans_fit125_w2v <- kmeans(w2v_bigrams_embedding, 125, iter.max = 30, nstart = 25)
# load w2v bigrams word embedding file
w2v_bigrams_embedding <- readRDS("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/w2v_bigrams_embedding.RData")
# CLUSTER ANALYSIS W2V BIGRAMS
# fit the k-means clustering with 125 clusters on w2v bigrams embedding.
kmeans_fit125_w2v <- kmeans(w2v_bigrams_embedding, 125, iter.max = 30, nstart = 25)
# Create data frame in which the cluster assignment is merged back to rows/word.
words_with_cluster125_w2v <- as.data.frame(cbind(row.names(w2v_bigrams_embedding), kmeans_fit125_w2v$cluster))
# add column names
names(words_with_cluster125_w2v) <- c("word", "kmeans125")
# find out to which cluster the word emotional_dysregulation is assigned
words_with_cluster125_w2v[words_with_cluster125_w2v$word == "emotional_dysregulation", ]
cluster125_w2v_112 <- subset(words_with_cluster125_w2v, subset=kmeans125 == 112)
View(cluster125_w2v_112)
# CLUSTER ANALYSIS W2V BIGRAMS
set.seed(88)
# fit the k-means clustering with 125 clusters on w2v bigrams embedding.
kmeans_fit125_w2v <- kmeans(w2v_bigrams_embedding, 125, iter.max = 30, nstart = 25)
# Create data frame in which the cluster assignment is merged back to rows/word.
words_with_cluster125_w2v <- as.data.frame(cbind(row.names(w2v_bigrams_embedding), kmeans_fit125_w2v$cluster))
# add column names
names(words_with_cluster125_w2v) <- c("word", "kmeans125")
# find out to which cluster the word emotional_dysregulation is assigned
words_with_cluster125_w2v[words_with_cluster125_w2v$word == "emotional_dysregulation", ]
cluster125_w2v_59 <- subset(words_with_cluster125_w2v, subset=kmeans125 == 59)
View(cluster125_w2v_59)
worcs::git_update()
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# makes it possible to call functions that are saved in separate R script
source("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/word_functions.R")
## Look at POS tags?
# reads file which contains the records into an object called recs
# this is were line 891 in manuscript file starts
recs <- read.csv("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
## Extract individual words
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
# make sure that the values in the column word do not contain any capitals.
df[, word := tolower(word)]
## Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")
# create an object with the number of unique documents (articles) in the data frame (df) and the number of unique (author key-) words in the data frame.
number_docs_words <- c(docs = length(unique(df$doc)), words =
length(unique(df$word)))
# check how many unique documents and words there are before excluding terms.
length(unique(df$doc))
length(unique(df$word))
## Exclude words
# create object with the terms that should be excluded
exclude_terms <- readLines("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/exclude_terms.txt")
# object with all the row numbers of author keywords that should be excluded from the data frame
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
# create new data frame that excludes all the row numbers that have an author keyword that should be excluded
df <- df[!exclude_these, ]
# check how many unique documents and how many unique words there are after excluding non substantive words.
length(unique(df$doc))
length(unique(df$word))
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# makes it possible to call functions that are saved in separate R script
source("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/word_functions.R")
# note that dict from word_function.R is overwritten here
dict <- read_yaml("yaml_dict.txt")
## Look at POS tags?
# reads file which contains the records into an object called recs
# this is were line 891 in manuscript file starts
recs <- read.csv("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
## Extract individual words
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
# make sure that the values in the column word do not contain any capitals.
df[, word := tolower(word)]
## Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")
# create an object with the number of unique documents (articles) in the data frame (df) and the number of unique (author key-) words in the data frame.
number_docs_words <- c(docs = length(unique(df$doc)), words =
length(unique(df$word)))
# save this information(# of articles and # of unique author keywords) in a yaml file
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
# check how many unique documents and words there are before excluding terms.
length(unique(df$doc))
length(unique(df$word))
## Exclude words
# create object with the terms that should be excluded
exclude_terms <- readLines("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/exclude_terms.txt")
# object with all the row numbers of author keywords that should be excluded from the data frame
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
# create new data frame that excludes all the row numbers that have an author keyword that should be excluded
df <- df[!exclude_these, ]
# check how many unique documents and how many unique words there are after excluding non substantive words.
length(unique(df$doc))
length(unique(df$word))
# Categorize words
res_cat <- cat_words(df$word, dict, handle_dups = "all")
# Check coding issues
res_cat$dup
head(res_cat$unmatched)
# Merge back with original data
df <- merge_df(df, res_cat$words, "word_coded")
# check the number of unique values in the column word_coded
length(unique(df$word_coded))
# Check which value rows have in the column words and the column word_coded. Note that word_coded are the words that are included in the analysis.
df[df$word == "mothers", c("word", "word_coded")]
df[df$word_coded == "parenting", c("word", "word_coded")]
df[df$word == "emotion socialization", c("word", "word_coded")]
# check words from figure 2
df[df$word == "emotion regulation", c("word", "word_coded")]
df[df$word_coded == "SES", c("word", "word_coded")]
df[df$word_coded == "age", c("word", "word_coded")]
# check a word that is not in the dictionary
df[df$word_coded == "aboriginal", c("word", "word_coded")]
# check a word that is not in the dictionary
df[df$word_coded == "aboriginal", c("word", "word_coded")]
View(df)
df$numDE <- lenght(df$DE)
df$numDE <- length(df$DE)
View(df)
df$numDE <- nchar(df$DE)
View(df)
df[df$numDE  >= 33, c("TI", "AU")]
df[df$numDE  >= 33, c("TI", "AU", "numDE", "DE")]
View(df)
View(df)
View(df)
df[df$numDE  == 542, c("TI", "AU", "numDE", "DE")]
df[df$numDE  == 524, c("TI", "AU", "numDE", "DE")]
df[df$TI == "INDEX OF SCIENTIFIC PRODUCTION DURING THE 5 YEARS OF THE MJCP", c("TI", "AU", "numDE", "DE")]
df[df$TI == "INDEX OF SCIENTIFIC PRODUCTION DURING THE 5 YEARS OF THE MJCP", c("TI", "AU", "numDE")]
summary(df$DE)
df$numDE2 <- df[, lengths(DE)]
df[df$numDE2  == 524, c("TI", "AU", "numDE", "DE")]
df[df$TI == "INDEX OF SCIENTIFIC PRODUCTION DURING THE 5 YEARS OF THE MJCP", c("TI", "AU", "numDE2")]
lenght(df[df$TI == "INDEX OF SCIENTIFIC PRODUCTION DURING THE 5 YEARS OF THE MJCP", "DE"])
length(df[df$TI == "INDEX OF SCIENTIFIC PRODUCTION DURING THE 5 YEARS OF THE MJCP", "DE"])
df[df$TI == "INDEX OF SCIENTIFIC PRODUCTION DURING THE 5 YEARS OF THE MJCP", "DE"]
df$numDE2 <- df[, length(DE)]
df[df$numDE2  == 524, c("TI", "AU", "numDE", "DE")]
df$numDE2 <- str_count(df$DE)
df[df$numDE2  == 524, c("TI", "AU", "numDE", "DE")]
df[df$TI == "INDEX OF SCIENTIFIC PRODUCTION DURING THE 5 YEARS OF THE MJCP", c("TI", "AU", "numDE2")]
df$numDE2 <- count(df$DE)
library(dplyr)
df$numDE2 <- count(df$DE)
df$numDE2 <- sapply(strsplit(df$DE, ";"), length)
df[df$numDE2  == 524, c("TI", "AU", "numDE", "DE")]
df[df$TI == "INDEX OF SCIENTIFIC PRODUCTION DURING THE 5 YEARS OF THE MJCP", c("TI", "AU", "numDE2")]
df[df$numDE2  >= 30, c("TI", "AU", "numDE2")]
unique(df[df$numDE2  >= 30, c("TI", "AU", "numDE2")])
df[df$TI == "\"WE LISTENED TO EACH OTHER\": SOCIOEMOTIONAL GROWTH IN LITERATURE CIRCLES", c("TI", "AU", "numDE2", "DE")]
check <- df[df$TI == "\"WE LISTENED TO EACH OTHER\": SOCIOEMOTIONAL GROWTH IN LITERATURE CIRCLES", c("TI", "AU", "numDE2", "DE")]
View(check)
length(df[1, "DE"])
check <- unique(df[df$TI == "\"WE LISTENED TO EACH OTHER\": SOCIOEMOTIONAL GROWTH IN LITERATURE CIRCLES", c("TI", "AU", "numDE2", "DE")])
View(check)
length(df$DE)
length(check$DE)
check
df$numDE <- sapply(strsplit(df$DE, ";"), length)
unique(df[df$numDE  >= 30, c("TI", "AU", "numDE", "doc_id")])
View(df)
View(df)
unique(df[df$numDE  >= 30, c("TI", "AU", "numDE", "doc")])
unique(df[df$numDE  >= 25, c("TI", "AU", "numDE", "doc")])
unique(df[df$numDE  >= 15, c("TI", "AU", "numDE", "doc")])
df[numDE == 22, ]
df[numDE == 22, "DE"]
unique(df[df$numDE  >= 15, c("TI", "AU", "numDE", "doc")])
# create dataframe for article with 337 author key words
check_DE <- df[df$doc == 3667, ]
View(check_DE)
# create dataframe for article with 337 author key words
check_DE <- df[df$doc == 5234, ]
View(check_DE)
worcs::git_update()
