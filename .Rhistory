df[, word := tolower(word)]
# Clean
df <- na.omit(df, cols = "word")
number_docs_words <- c(docs = length(unique(df$doc)), words = length(unique(df$word)))
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
# Exclude words
exclude_terms <- readLines("exclude_terms.txt")
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
df <- df[!exclude_these, ]
View(df)
worcs::git_update()
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
source("word_functions.R")
source("circle2.R")
#run_everything = FALSE
study1details <- read_yaml("study1_details.yml")
dict <- read_yaml("yaml_dict.txt")
## Look at POS tags?
recs <- read.csv("recs_final.csv")
recs <- as.data.table(recs)
if(!is.data.table(recs)){
browser()
}
recs[, "doc" := 1:nrow(recs)]
study1details <- list(dim_recs = dim(recs))
# Extract individual words
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
df <- merge_df(recs, df, "word")
df[, word := tolower(word)]
# Clean
df <- na.omit(df, cols = "word")
number_docs_words <- c(docs = length(unique(df$doc)), words = length(unique(df$word)))
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
# Exclude words
exclude_terms <- readLines("exclude_terms.txt")
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
df <- df[!exclude_these, ]
View(study1details)
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
source("word_functions.R")
source("circle2.R")
# Analysis 1:  Author keywords
#run_everything = FALSE
study1details <- read_yaml("study1_details.yml")
View(study1details)
dict <- read_yaml("yaml_dict.txt")
View(dict)
dict[["school"]]
View(dict)
## Look at POS tags?
recs <- read.csv("recs_final.csv")
View(recs)
recs <- as.data.table(recs)
if(!is.data.table(recs)){
browser()
}
View(study1details)
View(recs)
View(study1details)
View(recs)
View(recs)
summary(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
recs[, "doc" := 1:nrow(recs)]
View(recs)
View(recs)
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
View(study1details)
# Extract individual words
#
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
View(df)
?merge_df()
df <- merge_df(recs, df, "word")
View(df)
df[, word := tolower(word)]
View(df)
# Clean
# delete al t
df <- na.omit(df, cols = "word")
# Makes it possible to call functions that are saved in separate # R script
source("word_functions.R")
# Analysis 1:  Author keywords
# contains the dimensions of the recs dataframe
study1details <- read_yaml("study1_details.yml")
dict <- read_yaml("yaml_dict.txt")
## Look at POS tags?
# read file which contains the records into an object called recs
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
# Extract individual words
# create list with author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
View(df)
worcs::git_update()
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# Makes it possible to call functions that are saved in separate # R script
source("word_functions.R")
## Look at POS tags?
# read file which contains the records into an object called recs
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
# Extract individual words
# create list with author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
type(df)
typeof(df)
lenght(df)
length(df)
View(df)
summary(recs)
View(df)
sapply(df, length)
View(df)
df[[1]]
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# Makes it possible to call functions that are saved in separate # R script
source("word_functions.R")
# Analysis 1:  Author keywords
# contains the dimensions of the recs dataframe
study1details <- read_yaml("study1_details.yml")
dict <- read_yaml("yaml_dict.txt")
# Makes it possible to call functions that are saved in separate # R script
source("word_functions.R")
View(dict)
# Analysis 1:  Author keywords
# contains the dimensions of the recs dataframe
study1details <- read_yaml("study1_details.yml")
dict <- read_yaml("yaml_dict.txt")
## Look at POS tags?
# read file which contains the records into an object called recs
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
# Extract individual words
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
View(df)
# Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")
View(df)
# create an object with
number_docs_words <- c(docs = length(unique(df$doc)), words =
length(unique(df$word)))
View(recs)
sum(is.na(recs$DE))
6305 - 1274
# save this information in a yaml file
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
# Exclude words
# create object with the terms that should be excluded that are saved in a text file.
exclude_terms <- readLines("exclude_terms.txt")
exclude_terms
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
exclude_these
df <- df[!exclude_these, ]
View(df)
View(df)
View(df)
worcs::git_update()
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# makes it possible to call functions that are saved in separate R script
source("word_functions.R")
# note that dict from word_function.R is overwritten here
dict <- read_yaml("yaml_dict.txt")
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# makes it possible to call functions that are saved in separate R script
source("word_functions.R")
## Look at POS tags?
# reads file which contains the records into an object called recs
# this is were line 891 in manuscript file starts
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
## Extract individual words
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
# make sure that the values in the column word do not contain any capitals.
df[, word := tolower(word)]
## Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")
# create an object with the number of unique documents (articles) in the data frame (df) and the number of unique (author key-) words in the data frame.
number_docs_words <- c(docs = length(unique(df$doc)), words =
length(unique(df$word)))
# save this information(# of articles and # of unique author keywords) in a yaml file
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
## Exclude words
# create object with the terms that should be excluded
exclude_terms <- readLines("exclude_terms.txt")
# this does not seem to work? Give an empty integer
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
# does not seem to change anything to the dataframe
df_test <- df
df_test <- df_test[!exclude_these, ]
identical(df, df_test)
typeof(exclude_these)
exclude_these
View(df_test)
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# makes it possible to call functions that are saved in separate R script
source("word_functions.R")
## Look at POS tags?
# reads file which contains the records into an object called recs
# this is were line 891 in manuscript file starts
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
## Extract individual words
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
# make sure that the values in the column word do not contain any capitals.
df[, word := tolower(word)]
## Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")
# create an object with the number of unique documents (articles) in the data frame (df) and the number of unique (author key-) words in the data frame.
number_docs_words <- c(docs = length(unique(df$doc)), words =
length(unique(df$word)))
# save this information(# of articles and # of unique author keywords) in a yaml file
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
## Exclude words
# create object with the terms that should be excluded
exclude_terms <- readLines("exclude_terms.txt")
# object with all the row numbers of author keywords that should be excluded from the data frame
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
# create new data frame that excludes all the row numbers that have an author keyword that should be excluded
df <- df[!exclude_these, ]
View(df)
worcs::git_update()
rmarkdown::render("manuscript.Rmd")
View(dict)
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# makes it possible to call functions that are saved in separate R script
source("word_functions.R")
View(dict)
worcs::git_update()
install.packages("text2vec")
# Loading required libraries
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(Matrix)
library(ggplot2)
# Required library for GloVe
library(text2vec)
# prepare data
# this is were line 891 in manuscript file starts
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
View(study1details)
## Extract individual words
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
View(df)
worcs::git_update()
worcs::git_update()
# Loading required libraries
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(Matrix)
library(ggplot2)
# Required library for GloVe
library(text2vec)
# prepare data
# this is were line 891 in manuscript file starts
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
## Extract individual words
##### -> DIT IS WAARSCHIJNLIJK NIET NODIG MOET WEL ; EN HOOFDLETTERS WEGHALEN MAAR NIET WORD PER ROW.
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
# make sure that the values in the column word do not contain any capitals.
df[, word := tolower(word)]
# Loading script containing functions
source("word_functions.R")
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
# make sure that the values in the column word do not contain any capitals.
df[, word := tolower(word)]
View(recs)
# Loading script containing functions
source("word_functions.R")
# prepare data
# this is were line 891 in manuscript file starts
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
## Extract individual words
##### -> DIT IS WAARSCHIJNLIJK NIET NODIG MOET WEL ; EN HOOFDLETTERS WEGHALEN MAAR NIET WORD PER ROW.
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
View(df)
# make sure that the values in the column word do not contain any capitals.
df[, word := tolower(word)]
## Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")
# Not that the dataset is cleaned created a df in which each document is a row and the column DEclean contains the author keywords of the specific document.
df_new <- df %>%
group_by(word) %>%
group_by(doc) %>%
summarise(DEclean = str_c(word, collapse = " "))
library(tidyverse)
library(dplyr)
# Not that the dataset is cleaned created a df in which each document is a row and the column DEclean contains the author keywords of the specific document.
df_new <- df %>%
group_by(word) %>%
group_by(doc) %>%
summarise(DEclean = str_c(word, collapse = " "))
# Loading required libraries
library(stringr)
# Not that the dataset is cleaned created a df in which each document is a row and the column DEclean contains the author keywords of the specific document.
df_new <- df %>%
group_by(word) %>%
group_by(doc) %>%
summarise(DEclean = str_c(word, collapse = " "))
View(df_new)
# Not that the dataset is cleaned created a df in which each document is a row and the column DEclean contains the author keywords of the specific document.
df_new <- df %>%
select(doc, DE, word) %>%
group_by(word) %>%
group_by(doc) %>%
summarise(DEclean = str_c(word, collapse = " "))
View(df_new)
# Not that the dataset is cleaned created a df in which each document is a row and the column DEclean contains the author keywords of the specific document.
df_new <- df %>%
select(doc, DE, word) %>%
group_by(word) %>%
group_by(doc) %>%
summarise(DEclean = str_c(word, collapse = " "))
View(df_new)
View(df)
# create an object with the number of unique documents (articles) in the data frame (df) and the number of unique (author key-) words in the data frame.
number_docs_words <- c(docs = length(unique(df$doc)), words =
length(unique(df$word)))
## Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")
## Exclude words
# create object with the terms that should be excluded
exclude_terms <- readLines("exclude_terms.txt")
# object with all the row numbers of author keywords that should be excluded from the data frame
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
# create new data frame that excludes all the row numbers that have an author keyword that should be excluded
df <- df[!exclude_these, ]
# Now that the dataset is cleaned created a df in which each document is a row and the column DEclean contains the author keywords of the specific document. Shape the tokens back to their original form
df_new <- df %>%
group_by(word) %>%
group_by(doc) %>%
summarise(DEclean = str_c(word, collapse = " "))
View(df_new)
# We need to tokenize our already tokenized set as input for text2vec, re-use cleaned text in df_new
it <- itoken(df_new$DEclean,
tokenizer = word_tokenizer,
ids = df_new$doc,
progressbar = TRUE)
# create a vocabulary out of the tokenset (stopword removal and bi-grams are optional)
vocab <- create_vocabulary(it) # use uni-grams
# text2vec has the option to prune the vocabulary of low-frequent words
vocab <- prune_vocabulary(vocab, term_count_min = 5)
# What's in the vocabulary?
print(vocab)
# Vectorize word to integers
vectorizer <- vocab_vectorizer(vocab)
# Create a Term-Count-Matrix, by default it will use a skipgram window of 5 (symmetrical)
tcm <- create_tcm(it, vectorizer, skip_grams_window = 5L)
# maximum number of co-occurrences to use in the weighting function, we choose the entire token set divided by 100
x_max <- length(vocab$doc_count)/100
# set up the embedding matrix and fit model
glove_model <- GloVe$new(rank = 32, x_max = x_max)
glove_embedding = glove_model$fit_transform(tcm, n_iter = 20, convergence_tol = 0.01, n_threads = 4)
# combine main embedding and context embeddings (sum) into one matrix
glove_embedding = glove_embedding + t(glove_model$components) # the transpose of the context matrix
word <- glove_embedding["school", , drop = FALSE] # wat ligt er dicht bij 'school'
cos_sim = sim2(x = glove_embedding, y = word, method = "cosine", norm = "l2")
head(sort(cos_sim[,1], decreasing = TRUE), 10)
word <- glove_embedding["personality", , drop = FALSE] # wat ligt er dicht bij 'school'
cos_sim = sim2(x = glove_embedding, y = word, method = "cosine", norm = "l2")
head(sort(cos_sim[,1], decreasing = TRUE), 10)
worcs::git_update()
