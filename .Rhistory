summary(df_wordvecemb)
# check structure
str(df_wordvecemb)
#  transform data frame to matrix
mat_wordvecemb <- as.matrix(df_wordvecemb)
# the first column contains the words so we want to set the row names accordingly
rownames(mat_wordvecemb) <- mat_wordvecemb[,1]
# and then remove the first column
mat_wordvecemb <- mat_wordvecemb[,-1]
# check str of the matrix
str(mat_wordvecemb)
# Convert to numeric matrix
m <- apply(m, 1:40 ,as.numeric)
# Convert to numeric matrix
m <- apply(mat_wordvecemb, 1:40 ,as.numeric)
# Convert to numeric matrix
m <- apply(mat_wordvecemb, 40 ,as.numeric)
View(mat_wordvecemb)
dim(mat_wordvecemb)
# Convert to numeric matrix
m <- apply(mat_wordvecemb, 40 ,as.numeric)
# Convert to numeric matrix
m <- sapply(mat_wordvecemb, 40 ,as.numeric)
# Convert to numeric matrix
m <- sapply(mat_wordvecemb, 40 ,as.numeric())
# Convert to numeric matrix
m <- sapply(mat_wordvecemb, as.numeric)
View(m)
class(mat_wordvecemb)
class(mat)
class(m)
# test stack exchange
dim1 <- df_wordvecemb$dim1
dim2 <- df_wordvecemb$dim2
y[,1] <- as.matrix(sapply(dim1, as.numeric))
y <- data.frame(wordname, dim1, dim2)
wordname <- df_wordvecemb$word
y <- data.frame(wordname, dim1, dim2)
y[,1] <- as.matrix(sapply(dim1, as.numeric))
y[,2] <- as.matrix(sapply(dim2, as.numeric))
View(y)
row.names(y) <- wordname
str(y)
View(y)
str(df_wordvecemb)
mat <- t(df_wordvecemb)
View(mat)
str(mat)
# load csv into object
dict_wordvecemb <- read.csv("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/asreview_simulation/dict_wordvec.csv", header = FALSE)
# adjust the first column name to word
colnames(dict_wordvecemb)[1] <- "word"
# check structure of dataframe
str(dict_wordvecemb)
# remove certain characters from the column V2 which now is column of the type
# character and contains a string as value.
library(tidyverse)
# create new data frame that can be used for applying adjustments
df_wordvecemb <- dict_wordvecemb
# remove the [ character from V2
df_wordvecemb$V2 <-gsub("\\[","",as.character(df_wordvecemb$V2))
# remove the ] character from V2
df_wordvecemb$V2 <-gsub("\\]","",as.character(df_wordvecemb$V2))
# remove the \n character from V2
df_wordvecemb$V2 <-gsub("\\\n","",as.character(df_wordvecemb$V2))
# check if removing the characters went correctly
df_wordvecemb[1,"V2"]
# split column V2 into multiple columns
library(splitstackshape)
# separate on the space
df_wordvecemb <- cSplit(df_wordvecemb, "V2", " ")
# retain dimensions of data frame
dim(df_wordvecemb)
# rename the column names of the data frame.
# First column is named word and the other columns dim1-40
colnames(df_wordvecemb) <- c("word", paste0("dim", 1:40))
# check if there are any missings
summary(df_wordvecemb)
# check structure
str(df_wordvecemb)
# the first column contains the words so we want to set the row names accordingly
rownames(df_wordvecemb) <- df_wordvecemb[,1]
View(df_wordvecemb)
# the first column contains the words so we want to set the row names accordingly
rownames(df_wordvecemb) <- df_wordvecemb[ ,"word"]
# the first column contains the words so we want to set the row names accordingly
df <- df_wordvecemb[,-1]
rownames(df) <- df_wordvecemb[,1]
#  transform data frame to matrix
mat_wordvecemb <- as.matrix(df_wordvecemb)
# the first column contains the words so we want to set the row names accordingly
rownames(mat_wordvecemb) <- mat_wordvecemb[,1]
# and then remove the first column
mat_wordvecemb <- mat_wordvecemb[,-1]
View(mat_wordvecemb)
# check str of the matrix
str(mat_wordvecemb)
# convert matrix back to dataframe
df <- as.data.frame(mat_wordvecemb)
View(df)
# check structure of this dataframe
str(df)
df[,1:40] <- sapply(df[,1:40],as.character)
# check structure of this dataframe
str(df)
df <- sapply(df[,1:40],as.character)
df <- sapply(df[,1:40],as.numeric)
# check structure of this dataframe
str(df)
# convert matrix back to dataframe
df <- as.data.frame(mat_wordvecemb)
# check structure of this dataframe
str(df)
df[,1:40] <- sapply(df[,1:40],as.numeric)
# check structure of this dataframe
str(df)
# see what function t() does when applied on this data frame
testmat <- t(df)
View(testmat)
str(testmat)
CosineFun <- function(x, y){
# calculate the cosine similarity between two vectors: x and y
c <- sum(x*y) / (sqrt(sum(x * x)) * sqrt(sum(y * y)))
return(c)
}
CosineSim <- function(X) {
# calculate the pairwise cosine similarity between columns of the matrix X.
# initialize similarity matrix
m <- matrix(NA,
nrow = ncol(X),
ncol = ncol(X),
dimnames = list(colnames(X), colnames(X)))
cos <- as.data.frame(m)
# calculate the pairwise cosine similarity
for(i in 1:ncol(X)) {
for(j in i:ncol(X)) {
co_rate_1 <- X[which(X[, i] & X[, j]), i]
co_rate_2 <- X[which(X[, i] & X[, j]), j]
cos[i, j] <- CosineFun(co_rate_1, co_rate_2)
# fill in the opposite diagonal entry
cos[j, i] <- cos[i, j]
}
}
return(cos)
}
# this is not working. -> operations are possible only for numeric, logical or complex types. -> maybe I need to adjust the type of the matrix. Also might need to leave out t() because it is already a matrix
cosine_similarity <- CosineSim(t(df))
# takes a really long time because I am running it on 19467 words.
cosine_similarity <- CosineSim(t(df[1:40,]))
View(cosine_similarity)
# takes a really long time because I am running it on 19467 words for testing I will only run it on 500 word
cosine_similarity <- CosineSim(t(df[c(1:50, 300:350, 600:700, 845:945, 2000:2100, 18550:18700), ]))
diag(cosine.similarity) <- NA
diag(cosine_similarity) <- NA
library(devtools)
# install the development version of superheat
devtools::install_github("rlbarter/superheat")
# install the development version of superheat
devtools::install_github("rlbarter/superheat")
library(superheat)
superheat(cosine.similarity,
# place dendrograms on columns and rows
row.dendrogram = T,
col.dendrogram = T,
# make gridlines white for enhanced prettiness
grid.hline.col = "white",
grid.vline.col = "white",
# rotate bottom label text
bottom.label.text.angle = 90,
legend.breaks = c(-0.1, 0.1, 0.3, 0.5))
superheat(cosine_similarity,
# place dendrograms on columns and rows
row.dendrogram = T,
col.dendrogram = T,
# make gridlines white for enhanced prettiness
grid.hline.col = "white",
grid.vline.col = "white",
# rotate bottom label text
bottom.label.text.angle = 90,
legend.breaks = c(-0.1, 0.1, 0.3, 0.5))
View(df)
# takes a really long time because I am running it on 19467 words for testing I will only run it on 555 words
cosine_similarity <- CosineSim(t(df[c(1:50, 300:350, 600:700, 845:945, 2000:2100, 18550:18700, 5000:5250, 13840:14000), ]))
# takes a really long time because I am running it on 19467 words for testing I will only run it on 555 words
cosine_similarity <- CosineSim(t(df[c(1:50, 300:350, 600:700, 845:945, 2000:2100, 18550:18700, 5000:5250, 13840:14000, 8000:8033), ]))
# takes a really long time because I am running it on 19467 words for testing I will only run it on 1000 words
cosine_similarity <- CosineSim(t(df[c(1:50, 300:350, 600:700, 845:945, 2000:2100, 18550:18700, 5000:5250, 13840:14000, 8000:8032), ]))
# check dimensions
dim(cosine_similarity)
cosineSilhouette <- function(cosine.matrix, membership) {
# Args:
#   cosine.matrix: the cosine similarity matrix for the words
#   membership: the named membership vector for the rows and columns.
#               The entries should be cluster centers and the vector
#               names should be the words.
if (!is.factor(membership)) {
stop("membership must be a factor")
}
# note that there are some floating point issues:
# (some "1" entires are actually sliiightly larger than 1)
cosine.dissim <- acos(round(cosine.matrix, 10)) / pi
widths.list <- lapply(levels(membership), function(clust) {
# filter rows of the similarity matrix to words in the current cluster
# filter cols of the similarity matrix to words in the current cluster
cosine.matrix.inside <- cosine.dissim[membership == clust,
membership == clust]
# a: average dissimilarity of i with all other data in the same cluster
a <- apply(cosine.matrix.inside, 1, mean)
# filter rows of the similarity matrix to words in the current cluster
# filter cols of the similarity matrix to words NOT in the current cluster
other.clusters <- levels(membership)[levels(membership) != clust]
cosine.matrix.outside <- sapply(other.clusters, function(other.clust) {
cosine.dissim[membership == clust, membership == other.clust] %>%
apply(1, mean) # average over clusters
})
# b is the lowest average dissimilarity of i to any other cluster of
# which i is not a member
b <- apply(cosine.matrix.outside, 1, min)
# silhouette width is b - a
cosine.sil.width <- b - a
data.frame(word = names(cosine.sil.width), width = cosine.sil.width)
})
widths.list <- do.call(rbind, widths.list)
# join membership onto data.frame
membership.df <- data.frame(word = names(membership),
membership = membership)
widths.list <- left_join(widths.list, membership.df, by = "word")
return(widths.list)
}
set.seed(238942)
# calculate the average silhouette width for k=5, ..., 20
sil.width <- sapply(5:20, function(k) {
# generate k clusters
membership <- pam(cosine_similarity, k = k)
# calcualte the silhouette width for each observation
width <- cosineSilhouette(cosine_similarity,
membership = factor(membership$clustering))$width
return(mean(width))
})
library(knitr)
library(dplyr)
library(reshape2)
library(cluster)
library(ggplot2)
library(devtools)
# install the development version of superheat
devtools::install_github("rlbarter/superheat")
library(superheat)
# load csv into object
dict_wordvecemb <- read.csv("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/asreview_simulation/dict_wordvec.csv", header = FALSE)
# adjust the first column name to word
colnames(dict_wordvecemb)[1] <- "word"
# load csv into object
dict_wordvecemb <- read.csv("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/asreview_simulation/dict_wordvec.csv", header = FALSE)
# load csv into object
dict_wordvecemb <- read.csv("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/asreview_simulation/dict_wordvec.csv", header = FALSE)
# adjust the first column name to word
colnames(dict_wordvecemb)[1] <- "word"
# check structure of dataframe
str(dict_wordvecemb)
# remove certain characters from the column V2 which now is column of the type
# character and contains a string as value.
library(tidyverse)
# create new data frame that can be used for applying adjustments
df_wordvecemb <- dict_wordvecemb
# remove the [ character from V2
df_wordvecemb$V2 <-gsub("\\[","",as.character(df_wordvecemb$V2))
# remove the ] character from V2
df_wordvecemb$V2 <-gsub("\\]","",as.character(df_wordvecemb$V2))
# remove the \n character from V2
df_wordvecemb$V2 <-gsub("\\\n","",as.character(df_wordvecemb$V2))
# check if removing the characters went correctly
df_wordvecemb[1,"V2"]
# split column V2 into multiple columns
library(splitstackshape)
# separate on the space
df_wordvecemb <- cSplit(df_wordvecemb, "V2", " ")
# retain dimensions of data frame
dim(df_wordvecemb)
# rename the column names of the data frame.
# First column is named word and the other columns dim1-40
colnames(df_wordvecemb) <- c("word", paste0("dim", 1:40))
# check if there are any missings
summary(df_wordvecemb)
# for same reason rename the rownames does not work on the data frame so first convert to matrix
#  transform data frame to matrix
mat_wordvecemb <- as.matrix(df_wordvecemb)
# the first column contains the words so we want to set the row names accordingly
rownames(mat_wordvecemb) <- mat_wordvecemb[,1]
# and then remove the first column
mat_wordvecemb <- mat_wordvecemb[,-1]
# check str of the matrix
str(mat_wordvecemb)
# convert matrix back to dataframe
df <- as.data.frame(mat_wordvecemb)
# check structure of this data frame
str(df)
# change all columns to numeric
df[,1:40] <- sapply(df[,1:40],as.numeric)
# see what function t() does when applied on this data frame
testmat <- t(df)
str(testmat)
CosineFun <- function(x, y){
# calculate the cosine similarity between two vectors: x and y
c <- sum(x*y) / (sqrt(sum(x * x)) * sqrt(sum(y * y)))
return(c)
}
CosineSim <- function(X) {
# calculate the pairwise cosine similarity between columns of the matrix X.
# initialize similarity matrix
m <- matrix(NA,
nrow = ncol(X),
ncol = ncol(X),
dimnames = list(colnames(X), colnames(X)))
cos <- as.data.frame(m)
# calculate the pairwise cosine similarity
for(i in 1:ncol(X)) {
for(j in i:ncol(X)) {
co_rate_1 <- X[which(X[, i] & X[, j]), i]
co_rate_2 <- X[which(X[, i] & X[, j]), j]
cos[i, j] <- CosineFun(co_rate_1, co_rate_2)
# fill in the opposite diagonal entry
cos[j, i] <- cos[i, j]
}
}
return(cos)
}
# takes a really long time because I am running it on 19467 words for testing I will only run it on 1000 words
cosine_similarity <- CosineSim(t(df[c(1:50, 300:350, 600:700, 845:945, 2000:2100, 18550:18700, 5000:5250, 13840:14000, 8000:8032), ]))
cosineSilhouette <- function(cosine.matrix, membership) {
# Args:
#   cosine.matrix: the cosine similarity matrix for the words
#   membership: the named membership vector for the rows and columns.
#               The entries should be cluster centers and the vector
#               names should be the words.
if (!is.factor(membership)) {
stop("membership must be a factor")
}
# note that there are some floating point issues:
# (some "1" entires are actually sliiightly larger than 1)
cosine.dissim <- acos(round(cosine.matrix, 10)) / pi
widths.list <- lapply(levels(membership), function(clust) {
# filter rows of the similarity matrix to words in the current cluster
# filter cols of the similarity matrix to words in the current cluster
cosine.matrix.inside <- cosine.dissim[membership == clust,
membership == clust]
# a: average dissimilarity of i with all other data in the same cluster
a <- apply(cosine.matrix.inside, 1, mean)
# filter rows of the similarity matrix to words in the current cluster
# filter cols of the similarity matrix to words NOT in the current cluster
other.clusters <- levels(membership)[levels(membership) != clust]
cosine.matrix.outside <- sapply(other.clusters, function(other.clust) {
cosine.dissim[membership == clust, membership == other.clust] %>%
apply(1, mean) # average over clusters
})
# b is the lowest average dissimilarity of i to any other cluster of
# which i is not a member
b <- apply(cosine.matrix.outside, 1, min)
# silhouette width is b - a
cosine.sil.width <- b - a
data.frame(word = names(cosine.sil.width), width = cosine.sil.width)
})
widths.list <- do.call(rbind, widths.list)
# join membership onto data.frame
membership.df <- data.frame(word = names(membership),
membership = membership)
widths.list <- left_join(widths.list, membership.df, by = "word")
return(widths.list)
}
set.seed(238942)
sil.width <- sapply(5:20, function(k) {
# generate k clusters
membership <- pam(cosine_similarity, k = k)
# calcualte the silhouette width for each observation
width <- cosineSilhouette(cosine_similarity,
membership = factor(membership$clustering))$width
return(mean(width))
})
data.frame(k = 5:20, width = sil.width) %>%
ggplot(aes(x = k, y = width)) +
geom_line() +
geom_point() +
scale_y_continuous(name = "Avergae silhouette width")
library(cluster)
generateClusters <- function(similarity.mat, k.range, N) {
random.subset.list <- lapply(1:100, function(i) {
sample(1:nrow(similarity.mat), 0.9 * nrow(similarity.mat))
})
lapply(k.range, function(k) {
print(paste("k =", k))
lapply(1:N, function(i) {
# randomly sample 90% of words
cosine.sample <- similarity.mat[random.subset.list[[i]], random.subset.list[[i]]]
# perform clustering
pam.clusters <- pam(1 - cosine.sample, k = k, diss = TRUE)
})
})
}
# generate clusters ranging from 5 to 20 cluster groups for each of 100 subsamples
# This will take a little while to run
cluster.iterations <- generateClusters(cosine_similarity,
k.range = 5:20,
N = 100)
join.cluster.iterations <- lapply(cluster.iterations, function(list) {
# for each list of iterations (for a specific k),
# full-join the membership vectors into a data frame
# (there will be missing values in each column)
Reduce(function(x, y) full_join(x, y, by = "words"),
lapply(list, function(cluster.obj) {
df <- data.frame(words = names(cluster.obj$clustering),
clusters = cluster.obj$clustering)
}))
})
join.cluster.iterations <- lapply(join.cluster.iterations, function(x) {
colnames(x) <- c("words", paste0("membership", 1:100))
return(x)
})
# view the first 8 columns of the first data frame (correpsonding to k=5)
kable(head(join.cluster.iterations[[1]][, 1:8]))
# calculate the pairwise jaccard similarity between each of the cluster
# memberships accross the common words
# to avoid correlation, we do this pairwise between simulations 1 and 2,
# and then between simulations 3 and 4, and so on
library(Rcpp)
install.packages("Rcpp")
# calculate the pairwise jaccard similarity between each of the cluster
# memberships accross the common words
# to avoid correlation, we do this pairwise between simulations 1 and 2,
# and then between simulations 3 and 4, and so on
library(Rcpp)
find_similar_words <- function(word, embedding_matrix, n = 5) {
similarities <- embedding_matrix[word, , drop = FALSE] %>%
sim2(embedding_matrix, y = ., method = "cosine")
similarities[, 1] %>% sort(decreasing = TRUE) %>% head(n)
}
find_similar_words("friends", testmat,10)
# load csv into object
dict_wordvecemb <- read.csv("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/asreview_simulation/dict_wordvec.csv", header = FALSE)
# adjust the first column name to word
colnames(dict_wordvecemb)[1] <- "word"
# check structure of dataframe
str(dict_wordvecemb)
# remove certain characters from the column V2 which now is column of the type
# character and contains a string as value.
library(tidyverse)
# create new data frame that can be used for applying adjustments
df_wordvecemb <- dict_wordvecemb
# remove the [ character from V2
df_wordvecemb$V2 <-gsub("\\[","",as.character(df_wordvecemb$V2))
# remove the ] character from V2
df_wordvecemb$V2 <-gsub("\\]","",as.character(df_wordvecemb$V2))
# load in some useful libraries need to copy tutorial
library(knitr)
library(dplyr)
library(reshape2)
library(cluster)
library(ggplot2)
library(devtools)
# install the development version of superheat
# devtools::install_github("rlbarter/superheat")
library(superheat)
# load csv into object
dict_wordvecemb <- read.csv("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/asreview_simulation/dict_wordvec.csv", header = FALSE)
# adjust the first column name to word
colnames(dict_wordvecemb)[1] <- "word"
# check structure of dataframe
str(dict_wordvecemb)
# remove certain characters from the column V2 which now is column of the type
# character and contains a string as value.
library(tidyverse)
# create new data frame that can be used for applying adjustments
df_wordvecemb <- dict_wordvecemb
# remove the [ character from V2
df_wordvecemb$V2 <-gsub("\\[","",as.character(df_wordvecemb$V2))
# remove the ] character from V2
df_wordvecemb$V2 <-gsub("\\]","",as.character(df_wordvecemb$V2))
# remove the \n character from V2
df_wordvecemb$V2 <-gsub("\\\n","",as.character(df_wordvecemb$V2))
# check if removing the characters went correctly
df_wordvecemb[1,"V2"]
# split column V2 into multiple columns
library(splitstackshape)
# separate on the space
df_wordvecemb <- cSplit(df_wordvecemb, "V2", " ")
# retain dimensions of data frame
dim(df_wordvecemb)
# rename the column names of the data frame.
# First column is named word and the other columns dim1-40
colnames(df_wordvecemb) <- c("word", paste0("dim", 1:40))
# for same reason rename the rownames does not work on the data frame so first convert to matrix
#  transform data frame to matrix
mat_wordvecemb <- as.matrix(df_wordvecemb)
# the first column contains the words so we want to set the row names accordingly
rownames(mat_wordvecemb) <- mat_wordvecemb[,1]
# and then remove the first column
mat_wordvecemb <- mat_wordvecemb[,-1]
# check str of the matrix
str(mat_wordvecemb)
# convert matrix back to dataframe
df <- as.data.frame(mat_wordvecemb)
# check structure of this data frame
str(df)
# change all columns to numeric
df[,1:40] <- sapply(df[,1:40],as.numeric)
# check structure of this data frame
str(df)
# see what function t() does when applied on this data frame
testmat <- t(df)
str(testmat)
library(text2vec)
install.packages("text2vec")
worcs::git_update()
