renv::activate()
rmarkdown::render("manuscript.Rmd")
renv::status()
install.packages("papaja")
remotes::install_github("crsh/papaja", dependencies = TRUE, update = "never")
library('remotes')
install.packages("remotes")
remotes::install_github("crsh/papaja", dependencies = TRUE, update = "never")
install.packages("pattern.npl")
devtools::install_github("bnosac/pattern.nlp", INSTALL_opts = "--no-multiarch")
library(devtools)
remotes::install_github("bnosac/pattern.nlp", INSTALL_opts = "--no-multiarch")
renv::status()
renv:snapshot()
renv::snapshot()
remotes::install_github("bnosac/pattern.nlp", INSTALL_opts = "--no-multiarch")
devtools::install_github("bnosac/pattern.nlp", INSTALL_opts = "--no-multiarch")
install.packages("devtools")
devtools::install_github("bnosac/pattern.nlp", INSTALL_opts = "--no-multiarch")
renv:status()
renv::status()
devtools::install_github("bnosac/pattern.nlp", args = "--no-multiarch")
devtools::install_github("bnosac/pattern.nlp", INSTALL_opts = "--no-multiarch")
install.packages("PythoninR")
install.packages("PythoninR")
install.packages("PythonInR")
install.packages("PythonInR")
install.packages("reticulate")
devtools::install_github("bnosac/pattern.nlp", args = "--no-multiarch")
devtools::install_github("bnosac/pattern.nlp", INSTALL_opts = "--no-multiarch")
install.packages("~/Downloads/PythonInR_0.1-12.tar.gz", repos = NULL, type = "source")
install.packages("~/Downloads/PythonInR_0.1-12.tar.gz", repos = NULL, type = "source")
devtools::install_github("bnosac/pattern.nlp", INSTALL_opts = "--no-multiarch")
install.packages("findpython")
library(findpython)
can_find_python_cmd(required_modules = "pattern.db")
n
installed.packages(PythoninR)
install.packages(‘PythonInR’)
install.packages("PythonInR")
install.packages("~/Downloads/PythonInR_0.1-11.tar.gz", repos = NULL, type = "source")
install.packages("~/Documents/Reasearch Assistant Rgit/veni_sysrev/PythonInR_0.1-11.tar.gz", repos = NULL, type = "source")
renv::install("PythoninR")
renv/library
renv::activate()
rmarkdown::render("manuscript.Rmd")
renv::status()
renv::activate()
renv::activate()
rmarkdown::render("manuscript.Rmd")
renv::status()
remotes::install_github("bnosac/pattern.nlp", INSTALL_opts = "--no-multiarch")
worcs::git_update()
renv::status()
recs <- read.csv("recs_final.csv")
recs <- as.data.table(recs)
if(!is.data.table(recs)){
browser()
}
recs[, "doc" := 1:nrow(recs)]
study1details <- list(dim_recs = dim(recs))
# Extract individual words
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
df <- merge_df(recs, df, "word")
df[, word := tolower(word)]
# Clean
df <- na.omit(df, cols = "word")
number_docs_words <- c(docs = length(unique(df$doc)), words = length(unique(df$word)))
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
# Exclude words
exclude_terms <- readLines("exclude_terms.txt")
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
df <- df[!exclude_these, ]
library(stringr)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
source("word_functions.R")
source("circle2.R")
recs <- read.csv("recs_final.csv")
recs <- as.data.table(recs)
if(!is.data.table(recs)){
browser()
}
recs[, "doc" := 1:nrow(recs)]
study1details <- list(dim_recs = dim(recs))
# Extract individual words
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
df <- merge_df(recs, df, "word")
df[, word := tolower(word)]
# Clean
df <- na.omit(df, cols = "word")
number_docs_words <- c(docs = length(unique(df$doc)), words = length(unique(df$word)))
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
# Exclude words
exclude_terms <- readLines("exclude_terms.txt")
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
df <- df[!exclude_these, ]
View(study1details)
library(stringr)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
source("word_functions.R")
source("circle2.R")
#run_everything = FALSE
study1details <- read_yaml("study1_details.yml")
dict <- read_yaml("yaml_dict.txt")
## Look at POS tags?
recs <- read.csv("recs_final.csv")
recs <- as.data.table(recs)
if(!is.data.table(recs)){
browser()
}
recs[, "doc" := 1:nrow(recs)]
study1details <- list(dim_recs = dim(recs))
# Extract individual words
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
df <- merge_df(recs, df, "word")
df[, word := tolower(word)]
# Clean
df <- na.omit(df, cols = "word")
number_docs_words <- c(docs = length(unique(df$doc)), words = length(unique(df$word)))
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
# Exclude words
exclude_terms <- readLines("exclude_terms.txt")
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
df <- df[!exclude_these, ]
sessionInfo()
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
source("word_functions.R")
source("circle2.R")
#run_everything = FALSE
study1details <- read_yaml("study1_details.yml")
dict <- read_yaml("yaml_dict.txt")
## Look at POS tags?
recs <- read.csv("recs_final.csv")
recs <- as.data.table(recs)
if(!is.data.table(recs)){
browser()
}
recs[, "doc" := 1:nrow(recs)]
study1details <- list(dim_recs = dim(recs))
# Extract individual words
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
df <- merge_df(recs, df, "word")
df[, word := tolower(word)]
# Clean
df <- na.omit(df, cols = "word")
number_docs_words <- c(docs = length(unique(df$doc)), words = length(unique(df$word)))
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
# Exclude words
exclude_terms <- readLines("exclude_terms.txt")
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
df <- df[!exclude_these, ]
View(df)
worcs::git_update()
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
source("word_functions.R")
source("circle2.R")
#run_everything = FALSE
study1details <- read_yaml("study1_details.yml")
dict <- read_yaml("yaml_dict.txt")
## Look at POS tags?
recs <- read.csv("recs_final.csv")
recs <- as.data.table(recs)
if(!is.data.table(recs)){
browser()
}
recs[, "doc" := 1:nrow(recs)]
study1details <- list(dim_recs = dim(recs))
# Extract individual words
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
df <- merge_df(recs, df, "word")
df[, word := tolower(word)]
# Clean
df <- na.omit(df, cols = "word")
number_docs_words <- c(docs = length(unique(df$doc)), words = length(unique(df$word)))
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
# Exclude words
exclude_terms <- readLines("exclude_terms.txt")
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
df <- df[!exclude_these, ]
View(study1details)
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
source("word_functions.R")
source("circle2.R")
# Analysis 1:  Author keywords
#run_everything = FALSE
study1details <- read_yaml("study1_details.yml")
View(study1details)
dict <- read_yaml("yaml_dict.txt")
View(dict)
dict[["school"]]
View(dict)
## Look at POS tags?
recs <- read.csv("recs_final.csv")
View(recs)
recs <- as.data.table(recs)
if(!is.data.table(recs)){
browser()
}
View(study1details)
View(recs)
View(study1details)
View(recs)
View(recs)
summary(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
recs[, "doc" := 1:nrow(recs)]
View(recs)
View(recs)
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
View(study1details)
# Extract individual words
#
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
View(df)
?merge_df()
df <- merge_df(recs, df, "word")
View(df)
df[, word := tolower(word)]
View(df)
# Clean
# delete al t
df <- na.omit(df, cols = "word")
# Makes it possible to call functions that are saved in separate # R script
source("word_functions.R")
# Analysis 1:  Author keywords
# contains the dimensions of the recs dataframe
study1details <- read_yaml("study1_details.yml")
dict <- read_yaml("yaml_dict.txt")
## Look at POS tags?
# read file which contains the records into an object called recs
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
# Extract individual words
# create list with author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
View(df)
worcs::git_update()
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# Makes it possible to call functions that are saved in separate # R script
source("word_functions.R")
## Look at POS tags?
# read file which contains the records into an object called recs
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
# Extract individual words
# create list with author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
type(df)
typeof(df)
lenght(df)
length(df)
View(df)
summary(recs)
View(df)
sapply(df, length)
View(df)
df[[1]]
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# Makes it possible to call functions that are saved in separate # R script
source("word_functions.R")
# Analysis 1:  Author keywords
# contains the dimensions of the recs dataframe
study1details <- read_yaml("study1_details.yml")
dict <- read_yaml("yaml_dict.txt")
# Makes it possible to call functions that are saved in separate # R script
source("word_functions.R")
View(dict)
# Analysis 1:  Author keywords
# contains the dimensions of the recs dataframe
study1details <- read_yaml("study1_details.yml")
dict <- read_yaml("yaml_dict.txt")
## Look at POS tags?
# read file which contains the records into an object called recs
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
# Extract individual words
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
View(df)
# Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")
View(df)
# create an object with
number_docs_words <- c(docs = length(unique(df$doc)), words =
length(unique(df$word)))
View(recs)
sum(is.na(recs$DE))
6305 - 1274
# save this information in a yaml file
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
# Exclude words
# create object with the terms that should be excluded that are saved in a text file.
exclude_terms <- readLines("exclude_terms.txt")
exclude_terms
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
exclude_these
df <- df[!exclude_these, ]
View(df)
View(df)
View(df)
worcs::git_update()
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# makes it possible to call functions that are saved in separate R script
source("word_functions.R")
# note that dict from word_function.R is overwritten here
dict <- read_yaml("yaml_dict.txt")
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# makes it possible to call functions that are saved in separate R script
source("word_functions.R")
## Look at POS tags?
# reads file which contains the records into an object called recs
# this is were line 891 in manuscript file starts
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
## Extract individual words
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
# make sure that the values in the column word do not contain any capitals.
df[, word := tolower(word)]
## Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")
# create an object with the number of unique documents (articles) in the data frame (df) and the number of unique (author key-) words in the data frame.
number_docs_words <- c(docs = length(unique(df$doc)), words =
length(unique(df$word)))
# save this information(# of articles and # of unique author keywords) in a yaml file
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
## Exclude words
# create object with the terms that should be excluded
exclude_terms <- readLines("exclude_terms.txt")
# this does not seem to work? Give an empty integer
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
# does not seem to change anything to the dataframe
df_test <- df
df_test <- df_test[!exclude_these, ]
identical(df, df_test)
typeof(exclude_these)
exclude_these
View(df_test)
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# makes it possible to call functions that are saved in separate R script
source("word_functions.R")
## Look at POS tags?
# reads file which contains the records into an object called recs
# this is were line 891 in manuscript file starts
recs <- read.csv("recs_final.csv")
# convert object into data table
recs <- as.data.table(recs)
# if recs is not an object of type data table
# then code execution will be paused?
if(!is.data.table(recs)){
browser()
}
# add column called doc that contains the row number.
recs[, "doc" := 1:nrow(recs)]
# create object that is a list with the dimensions of the recs data frame
study1details <- list(dim_recs = dim(recs))
## Extract individual words
# create list with (separated) author keywords of each article
df <- lapply(recs$DE, function(x){strsplit(x, split = "; ")[[1]]})
# merge_df is a function from word_function.R. In short, the function unlist() is applied to the list object that has been put into the function (in this case df) and adds the output/result of this to the new column.
df <- merge_df(recs, df, "word")
# make sure that the values in the column word do not contain any capitals.
df[, word := tolower(word)]
## Clean
# delete all the rows that contain a missing value in the column word
df <- na.omit(df, cols = "word")
# create an object with the number of unique documents (articles) in the data frame (df) and the number of unique (author key-) words in the data frame.
number_docs_words <- c(docs = length(unique(df$doc)), words =
length(unique(df$word)))
# save this information(# of articles and # of unique author keywords) in a yaml file
yaml::write_yaml(number_docs_words, "study1_number_docs_words.txt")
## Exclude words
# create object with the terms that should be excluded
exclude_terms <- readLines("exclude_terms.txt")
# object with all the row numbers of author keywords that should be excluded from the data frame
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df$word)))
# create new data frame that excludes all the row numbers that have an author keyword that should be excluded
df <- df[!exclude_these, ]
View(df)
worcs::git_update()
rmarkdown::render("manuscript.Rmd")
View(dict)
# Loading required libraries
library(stringr)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(udpipe)
library(igraph)
library(wordcloud)
library(Matrix)
library(ggplot2)
library(yaml)
# makes it possible to call functions that are saved in separate R script
source("word_functions.R")
View(dict)
worcs::git_update()
