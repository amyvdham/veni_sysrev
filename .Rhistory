# load the manuscript pre-processed file (without textrank algorithm and dict filter having been applied)
df_before_excl <- readRDS("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/study2_df.RData")
# Exclude words
# make sure to only include nouns and adjectives.
df_kw <- df_before_excl[upos %in% c("NOUN", "ADJ"), ]
# make sure to only include strings that start with a letter. (. -> and end with any character?)
df_kw <- df_kw[grepl("^[a-zA-Z].", df_kw$lemma), ]
# exclude methodological terms and similar non-substantive words
exclude_terms <- readLines("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/exclude_terms.txt")
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df_kw$lemma)))
df_kw[21, "lemma"]
df_kw <- df_kw[-exclude_these, ]
df_kw[df_kw$lemma == "child", ]
# load the manuscript pre-processed file (without textrank algorithm and dict filter having been applied)
df_before_excl <- readRDS("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/study2_df.RData")
# Exclude words
# make sure to only include nouns and adjectives.
df_kw <- df_before_excl[upos %in% c("NOUN", "ADJ"), ]
# make sure to only include strings that start with a letter. (. -> and end with any character?)
df_kw <- df_kw[grepl("^[a-zA-Z].", df_kw$lemma), ]
# exclude methodological terms and similar non-substantive words
exclude_terms <- readLines("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/exclude_terms.txt")
exclude_these <- unique(unlist(lapply(exclude_terms, grep, x = df_kw$lemma)))
# exclude_these contains the integers of the words (fit the regular expressions) that are in the exclude_terms file. One of the words that is in there is row 21.
df_kw[21, "lemma"]
df_kw[390, "lemma"]
df_kw[724, "lemma"]
# remove all those rows that include one of the terms that should be excluded
df_after_exclusion <- df_kw[-exclude_these, ]
df_kw[df_kw$lemma == "child", ]
df_after_exclusion[df_after_exclusion$lemma == "child", ]
df_after_exclusion[df_after_exclusion$token == "child", ]
# In the cluster analysis I found that the word correlation was still in the embedding so will check on this word
df_kw[df_kw$lemma == "correlation", ]
df_after_exclusion[df_after_exclusion$lemma == "correlation", ]
# In the cluster analysis I found that the word analysis was still in the embedding so will check on this word
df_kw[df_kw$lemma == "analysis", ]
df_after_exclusion[df_after_exclusion$lemma == "analysis", ]
# -> It seems that this have correctly been excluded. However I might that because of the splitting at - and / these terms have found there way back into the data frame.
# load the data frame that includes the token filter column.
check_filter_token <- readRDS("/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/study2_df_token.RData")
View(check_filter_token)
# check on the word analysis
check_filter_token[check_filter_token$filter_token == "analysis", c("lemma", "filter_token")]
# check on the word correlation
check_filter_token[check_filter_token$filter_token == "correlation", c("lemma", "filter_token")]
# In the cluster analysis I found that the word confounder was still in the embedding so will check on this word
df_kw[df_kw$lemma == "confounder", ]
df_after_exclusion[df_after_exclusion$lemma == "confounder", ]
# In the cluster analysis I found that the word confounder was still in the embedding so will check on this word
df_kw[df_kw$lemma == "confounder", ]
df_after_exclusion[df_after_exclusion$lemma == "confounder", ]
# In the cluster analysis I found that the word control was still in the embedding so will check on this word
df_kw[df_kw$lemma == "control", ]
df_after_exclusion[df_after_exclusion$lemma == "control", ]
# check on the word correlation
check_filter_token[check_filter_token$filter_token == "finding", c("lemma", "filter_token")]
# check on the word finding
df_kw[df_kw$lemma == "finding", ]
df_after_exclusion[df_after_exclusion$lemma == "finding", ]
check_filter_token[check_filter_token$filter_token == "finding", c("lemma", "filter_token")]
check_filter_token[check_filter_token$filter_token == "finding", c("token", "lemma", "filter_token")]
# check on the word finding
df_kw[df_kw$lemma == "control", ]
df_after_exclusion[df_after_exclusion$lemma == "control", ]
check_filter_token[check_filter_token$filter_token == "control", c("token", "lemma", "filter_token")]
worcs::git_update()
# load libraries
library(dplyr)
library(cluster)
library(ggplot2)
library(devtools)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
# libraries dbscan
library(fpc)
library(dbscan)
set.seed(88)
# load glove word embedding file
glove_embedding <- readRDS("glove_embedding.RData")
# check structure
str(glove_embedding)
setwd("~/Documents/Research_Assistant_Rgit/veni_sysrev/amy")
# load glove word embedding file
glove_embedding <- readRDS("glove_embedding.RData")
# check structure
str(glove_embedding)
# Compute DBSCAN
db <- dbscan::dbscan(glove_embedding, 8, 5)
# Print DBSCAN results
print(db)
# cluster membership
db$cluster
# Plot DBSCAN results
plot(db, glove_embedding, main = "DBSCAN", frame = FALSE)
# determining optimal eps value
dbscan::kNNdistplot(glove_embedding, k =  5)
abline(h = 0.15, lty = 2)
# try dbscan met eps = 4
db4 <- dbscan::dbscan(glove_embedding, 4, 5)
?dbscan()
# try dbscan with smaller eps. : eps = 0.10
db10_10 <- dbscan::dbscan(glove_embedding, 0.10, 10)
print(db10_10)
# try dbscan with smaller eps. : eps = 0.10
db10_10 <- dbscan::dbscan(glove_embedding, 0.10, 4)
print(db10_10)
# try dbscan with lager eps. : eps = 0.20
db.20_4 <- dbscan::dbscan(glove_embedding, 0.20, 4)
print(db.20_4)
# try dbscan with lager eps. : eps = 0.35
db.35_4 <- dbscan::dbscan(glove_embedding, 0.35, 4)
print(db.35_4)
# try dbscan with lager eps. : eps = 0.35
db.50_4 <- dbscan::dbscan(glove_embedding, 0.50, 4)
print(db.50_4)
# try dbscan with lager eps. : eps = 0.35
db1.5_4 <- dbscan::dbscan(glove_embedding, 1.5, 4)
print(db1.5_4)
# try dbscan with lager eps. : eps = 0.35
db1.5_4 <- dbscan::dbscan(glove_embedding, 1.5, 8)
print(db1.5_4)
# try dbscan with lager eps. : eps = 0.35
db1.5_4 <- dbscan::dbscan(glove_embedding, 1.5, 10000)
print(db1.5_4)
ln(12743)
install.packages("SciViews")
# determine minPts
library(SciViews)
View(glove_embedding)
ln(12743)
# determining optimal eps value
dbscan::kNNdistplot(glove_embedding, k =  9.5)
# determining optimal eps value
dbscan::kNNdistplot(glove_embedding, k =  9)
abline(h = 0.15, lty = 2)
# determining optimal eps value
dbscan::kNNdistplot(glove_embedding, k =  9)
abline(h = 7.9, lty = 2)
# based on the running the codelines above try dbscan with minPts = 9 and eps = 7.9
db_7.9_9 <- dbscan::dbscan(glove_embedding, 7.9, 9)
print(db_7.9_9)
db_4.6_9 <- dbscan::dbscan(glove_embedding, 4.6, 9)
print(db_4.6_9)
db_4.6_9$cluster
# Create data frame in which the cluster assignment is merged back to rows/word.
kw_with_cluster <- as.data.frame(cbind(row.names(glove_embedding), db_4.6_9$cluster))
View(kw_with_cluster)
names(kw_with_cluster) <- c("word", "dbscan7")
View(kw_with_cluster)
cluster4 <- subset(kw_with_cluster, subset=dbscan7 == 4)
View(cluster4)
print(db_4.6_9)
cluster6 <- subset(kw_with_cluster, subset=dbscan7 == 6)
View(cluster6)
cluster1 <- subset(kw_with_cluster, subset=dbscan7 == 1)
View(cluster1)
cluster2 <- subset(kw_with_cluster, subset=dbscan7 == 2)
View(cluster2)
cluster4 <- subset(kw_with_cluster, subset=dbscan7 == 4)
cluster5 <- subset(kw_with_cluster, subset=dbscan7 == 5)
View(cluster5)
cluster7 <- subset(kw_with_cluster, subset=dbscan7 == 7)
View(cluster7)
View(cluster6)
View(cluster2)
View(cluster7)
2*300
# I have also read somewhere that you should set minPts to 2*dim. Which in our case means 2*300 = 600. Let try what happens if we do that
# determining optimal eps value
dbscan::kNNdistplot(glove_embedding, k =  600)
abline(h = 6.3, lty = 2)
abline(h = 6.5, lty = 2)
abline(h = 9, lty = 2)
abline(h = 9.2, lty = 2)
# based on the running the codelines above try dbscan with minPts = 600 and eps = 6.5
db_6.5_600 <- dbscan::dbscan(glove_embedding, 6.5, 600)
print(db_6.5_600)
# load libraries
library(dplyr)
library(cluster)
library(ggplot2)
library(devtools)
library(data.table, quietly = TRUE, warn.conflicts = FALSE)
set.seed(88)
# load existing word embeddings
# load glove vectors into R
vectors_glove <- data.table::fread('glove.840B.300d.txt', data.table = F,  encoding = 'UTF-8', quote="")
# rename the columns
colnames(vectors_glove) <- c('word',paste('dim',1:300,sep = '_'))
# load data frame with column with selection of words to include in analysis.
df_incltoken <- readRDS("filter_token.RData")
# create df in which only the words that we want to be included are kept
token_embedding <- subset(vectors_glove, word %in% df_incltoken$filter_token)
# check number of unique words
length(unique((token_embedding$word)))
# non-GloVe: check which words are in the token filter but are not in the feature matrix and are therefore lost (unwanted).
lost_tokens <- subset(df_incltoken, !(filter_token %in% token_embedding $word))
length(unique((token_embedding$word))) + length(unique((lost_tokens$filter_token)))
# -> 14860. Which is equal to the line of code below.
length(unique((df_incltoken$filter_token)))
length(unique((token_embedding$word))) + length(unique((lost_tokens$filter_token)))
# -> 14860. Which is equal to the line of code below.
length(unique((df_incltoken$filter_token)))
# convert the first column, word, to row index.
library(tidyverse)
glove_embedding <- token_embedding %>%
remove_rownames() %>%
column_to_rownames(var = 'word')
# convert dataframe to a matrix
glove_embedding <- as.matrix(glove_embedding)
str(glove_embedding)
# save the glove embedding to which the filter is applied so this can be easily loaded into other scripts
saveRDS(glove_embedding, "/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/glove_embedding.RData")
library(text2vec)
# create function to find similar words based on cosine distance
find_similar_words <- function(word, embedding_matrix, n = 5) {
similarities <- embedding_matrix[word, , drop = FALSE] %>%
sim2(embedding_matrix, y = ., method = "cosine")
similarities[, 1] %>% sort(decreasing = TRUE) %>% head(n)
}
# Run function on the word health and see the 25 closest words based on cosine similarity.
find_similar_words("health",glove_embedding,25)
# fit the k-means clustering with 100 clusters
k_means_fit <- kmeans(glove_embedding, 100, iter.max = 30, nstart = 25)
# look at the size of the clusters
k_means_fit$size
min(k_means_fit$size)
max(k_means_fit$size)
# The cost function in kmeans is the total sum of the squares
k_means_fit$totss
# results
k_means_fit
# Create data frame in which the cluster assignment is merged back to rows/word.
words_with_cluster <- as.data.frame(cbind(row.names(glove_embedding), k_means_fit$cluster))
# add column names
names(words_with_cluster) <- c("word", "kmeans100")
# save this data frame which contains a column with words and a column with to which cluster they belong
saveRDS(words_with_cluster, "/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/clustering100.RData")
# make a df for the first 5 cluster results, quickly "eyeball" results
cluster1 <- subset(words_with_cluster, subset=kmeans100 == 1)
cluster2 <- subset(words_with_cluster, subset=kmeans100 == 2)
cluster3 <- subset(words_with_cluster, subset=kmeans100 == 3)
cluster4 <- subset(words_with_cluster, subset=kmeans100 == 4)
cluster5 <- subset(words_with_cluster, subset=kmeans100 == 5)
View(cluster5)
# Mother
# find out in which cluster the word mother is assigned
words_with_cluster[words_with_cluster$word == "mother", ]
# make a df of cluster 82
cluster82 <- subset(words_with_cluster, subset = kmeans100 == 82)
# I did not setseeded the cluster analysis yet so want to compare the difference between the two clusters that contain the word mother. -> Can not rerun this code now that I have set.seeded the analysis but it is important to be aware that every time you run the analysis and do not set.seed, the clusters will be different. The 3 times I have now run the analysis the cluster containing mother had either 71, 70 or 86 observations. Final time this cluster had even 112 observations.
diff_setseed <- subset(cluster6, !(word %in% cluster26$word))
# Health
# find out in which cluster the word health is assigned
words_with_cluster[words_with_cluster$word == "health", ]
# make a df of cluster 26
cluster26 <- subset(words_with_cluster, subset=kmeans100 == 26)
# Environment
# find out in which cluster the word environment is assigned
words_with_cluster[words_with_cluster$word == "environment", ]
# make a df of cluster 28
cluster28 <- subset(words_with_cluster, subset=kmeans100 == 28)
# Depression
# find out to which cluster the word depression is assigned so that I can check if all the forms of depression are in there.
words_with_cluster[words_with_cluster$word == "depression", ]
# make a df of cluster 31
cluster31 <- subset(words_with_cluster, subset=kmeans100 == 31)
# ->  If I look at the token_embedding dataframe and type depre in the filter within the word column I get the following words: nondepressed, antidepressant depressed, depression, depressive. It is surprising that some of these words fall in a different cluster. We wold expect at least depressed, depression and depressive to fall into the same cluster.
words_with_cluster[words_with_cluster$word == "depressed", ]
words_with_cluster[words_with_cluster$word == "depressive", ]
words_with_cluster[words_with_cluster$word == "nondepressed", ]
words_with_cluster[words_with_cluster$word == "antidepressant", ]
# lets check the clusters that depressed and depressive belong to.
# make a df of cluster 43 (depressed)
cluster43 <- subset(words_with_cluster, subset=kmeans100 == 43)
# make a df of cluster 36 (depressive)
cluster36 <- subset(words_with_cluster, subset=kmeans100 == 36)
# kelly
# find out in which cluster the word Kelly is assigned so that I can check if all names are put together for example.
words_with_cluster[words_with_cluster$word == "kelly", ]
# cortisol
# find out in which cluster the word cortisol is assigned
words_with_cluster[words_with_cluster$word == "cortisol", ]
# make a df of cluster 100
cluster100 <- subset(words_with_cluster, subset=kmeans100 == 100)
# empathy
# find out in which cluster the word empathy is assigned
words_with_cluster[words_with_cluster$word == "empathy", ]
# make a df of cluster 30
cluster30 <- subset(words_with_cluster, subset = kmeans100 == 30)
# check the smallest cluster
cluster20 <- subset(words_with_cluster, subset = kmeans100 == 20)
# check the largest cluster
cluster98 <- subset(words_with_cluster, subset = kmeans100 == 98)
# check another large cluster
cluster17 <- subset(words_with_cluster, subset = kmeans100 == 17)
# check another large cluster
cluster37 <- subset(words_with_cluster, subset = kmeans100 == 37)
# check cluster number 28
cluster28 <- subset(words_with_cluster, subset = kmeans100 == 28)
View(cluster28)
# check cluster number 69
cluster69 <- subset(words_with_cluster, subset = kmeans100 == 69)
View(cluster69)
# create new subset data frame
embedding_cluster43 <- subset(glove_embedding, rownames(glove_embedding) %in% cluster43$word)
# fit k-means
k_means_fit3_cluster43 <- kmeans(embedding_cluster43, 3, iter.max = 30, nstart = 25)
# look at the results
# obtain the centroids
k_means_fit3_cluster43$centers
# look at the results
# look at the size of the clusters
k_means_fit3_cluster43$size
k_means_fit3_cluster43
# Create data frame in which the merge cluster assignment back to rows/word.
words_with_cluster43_3 <- as.data.frame(cbind(row.names(embedding_cluster43), k_means_fit3_cluster43$cluster))
# add column names
names(words_with_cluster43_3) <- c("word", "kmeans3")
# make a df for the 3 cluster results
cluster43_1 <- subset(words_with_cluster43_3, subset=kmeans3 == 1)
cluster43_2 <- subset(words_with_cluster43_3, subset=kmeans3 == 2)
cluster43_3 <- subset(words_with_cluster43_3, subset=kmeans3 == 3)
# visualize the k-means (with k = 3) clusters
fviz_cluster(k_means_fit3_cluster43, data = embedding_cluster43,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
# visualize the k-means (with k = 3) clusters
library(factoextra)
fviz_cluster(k_means_fit3_cluster43, data = embedding_cluster43,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
# Elbow method
fviz_nbclust(embedding_cluster43, kmeans, method = "wss") + geom_vline(xintercept = 7, linetype = 2) + # add line for better visualisation.
labs(subtitle = "Elbow method") # add subtitle
# Silhouette method
fviz_nbclust(embedding_cluster43, kmeans, method = "silhouette") +
labs(subtitle = "Silhouette method")
# Do not run, takes a really long time. Bring down nboot.
# Gap statistic
fviz_nbclust(embedding_cluster43, kmeans,
iter.max = 30,
nstart = 25,
method = "gap_stat",
nboot = 5 # reduce it for lower computation time (but less precise results)
) +
labs(subtitle = "Gap statistic method")
# RUN ANALYSIS WITH 8 CLUSTERS
# fit kmeans with 8 clusters
k_means_fit8_cluster43 <- kmeans(embedding_cluster43, 8, iter.max = 30, nstart = 25)
sil <- silhouette(k_means_fit8_cluster43$cluster, dist(embedding_cluster43))
fviz_silhouette(sil)
# # Create data frame in which the cluster assignment is merged back to rows/words.
words_with_cluster43_8 <- as.data.frame(cbind(row.names(embedding_cluster43), k_means_fit8_cluster43$cluster))
# add column names
names(resulting_clusters) <- c("word", "kmeans8")
# add column names
names(words_with_cluster43_8) <- c("word", "kmeans8")
# cluster with highest silhouette value
cluster6_highestsil <- subset(words_with_cluster43_8, subset = kmeans10 == 6)
# cluster with highest silhouette value
cluster6_highestsil <- subset(words_with_cluster43_8, subset = kmeans8 == 6)
View(cluster6_highestsil)
# visualize the k-means (with k = 8) clusters
fviz_cluster(k_means_fit9_cluster43, data = embedding_cluster43,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#3CB043", "#B2D3C2", "#354A21", "#EA3C53", "#8D021F", "#8F00FF", "#a88b32"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
# visualize the k-means (with k = 8) clusters
fviz_cluster(k_means_fit8_cluster43, data = embedding_cluster43,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#3CB043", "#B2D3C2", "#354A21", "#EA3C53", "#8D021F", "#8F00FF", "#a88b32"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
# create new subset data frame
embedding_cluster37 <- subset(glove_embedding, rownames(glove_embedding) %in% cluster37$word)
# Silhouette method for determining k
fviz_nbclust(embedding_cluster37, kmeans, method = "silhouette") +
labs(subtitle = "Silhouette method")
# fit k-means
k_means_fit5_cluster37 <- kmeans(embedding_cluster37, 5, iter.max = 30, nstart = 25)
# look at the size of the clusters
k_means_fit5_cluster37$size
# look at the results
k_means_fit5_cluster37
# Create data frame in which the merge cluster assignment back to rows/word.
words_with_cluster37_5 <- as.data.frame(cbind(row.names(embedding_cluster37), k_means_fit5_cluster37$cluster))
# add column names
names(words_with_cluster37_5 ) <- c("word", "kmeans5")
# make a df for the first 3 clusters
cluster37_1 <- subset(words_with_cluster37_5, subset=kmeans5 == 1)
cluster37_2 <- subset(words_with_cluster37_5, subset=kmeans5 == 2)
cluster37_3 <- subset(words_with_cluster37_5, subset=kmeans5 == 3)
View(cluster37_1)
View(cluster37_2)
View(cluster37_3)
# visualize the k-means (with k = 3) clusters
fviz_cluster(k_means_fit5_cluster37, data = embedding_cluster37,
palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07", "#8F00FF"),
ellipse.type = "euclid", # Concentration ellipse
star.plot = TRUE, # Add segments from centroids to items
repel = TRUE, # Avoid label overplotting (slow)
ggtheme = theme_minimal()
)
# fit the k-means clustering with 119 clusters
k_means_fit119 <- kmeans(glove_embedding, 119, iter.max = 30, nstart = 25)
View(cluster30)
# look at the size of the clusters
k_means_fit119$size
min(k_means_fit119$size)
max(k_means_fit119$size)
# The cost function in kmeans is the total sum of the squares
k_means_fit119$totss
# check results
k_means_fit119
# Create data frame in which the merge cluster assignment back to rows/word.
words_with_cluster119 <- as.data.frame(cbind(row.names(glove_embedding), k_means_fit119$cluster))
# add column names
names(words_with_cluster119) <- c("word", "kmeans119")
# save this data frame which contains a column with words and a column with to which cluster they belong
saveRDS(words_with_cluster119, "/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/clustering119.RData")
# check the largest cluster with 270 observations
cluster119_92 <- subset(words_with_cluster119,
subset=kmeans119 == 92)
# look at the size of the clusters
k_means_fit119$size
# check the largest cluster with 281 observations
cluster119_83 <- subset(words_with_cluster119,
subset=kmeans119 == 83)
# check the largest cluster with 281 observations
cluster119_73 <- subset(words_with_cluster119,
subset=kmeans119 == 73)
# check the largest cluster with 281 observations
cluster119_74 <- subset(words_with_cluster119,
subset=kmeans119 == 74)
View(cluster119_74)
# check the smallest cluster with 32 observations
cluster119_20 <- subset(words_with_cluster119,
subset=kmeans119 == 20)
View(cluster119_20)
# Health
# find out in which cluster the word health is assigned
words_with_cluster119[words_with_cluster119$word == "health", ]
# make a df of cluster 58
cluster119_58 <- subset(words_with_cluster119,
subset=kmeans119 == 58)
# Depression
# find out in which cluster the word depression is assigned
words_with_cluster119[words_with_cluster119$word == "depression", ]
# make a df of cluster 10
cluster119_10 <- subset(words_with_cluster119,
subset=kmeans119 == 10)
View(cluster119_10)
words_with_cluster119[words_with_cluster119$word == "nondepressed", ]
words_with_cluster119[words_with_cluster119$word == "antidepressant", ]
# I did not setseeded the cluster analysis yet so want to compare the difference between the two clusters that contain the word mother. -> Can not rerun this code now that I have set.seeded the analysis but it is important to be aware that every time you run the analysis and do not set.seed, the clusters will be different. The 3 times I have now run the analysis the cluster containing mother had either 71, 70 or 86 observations. Final time this cluster had even 112 observations.
set.seed(88)
# fit the k-means clustering with 119 clusters
k_means_fit119 <- kmeans(glove_embedding, 119, iter.max = 30, nstart = 25)
# look at the size of the clusters
k_means_fit119$size
min(k_means_fit119$size)
max(k_means_fit119$size)
# The cost function in kmeans is the total sum of the squares
k_means_fit119$totss
# check results
k_means_fit119
# Create data frame in which the merge cluster assignment back to rows/word.
words_with_cluster119 <- as.data.frame(cbind(row.names(glove_embedding), k_means_fit119$cluster))
# add column names
names(words_with_cluster119) <- c("word", "kmeans119")
# save this data frame which contains a column with words and a column with to which cluster they belong
saveRDS(words_with_cluster119, "/Users/amyvanderham/Documents/Research_Assistant_Rgit/veni_sysrev/amy/clustering119.RData")
# look at the size of the clusters
k_means_fit119$size
# check the largest cluster with 246 observations
cluster119_55 <- subset(words_with_cluster119,
subset=kmeans119 == 55)
View(cluster119_55)
# check the smallest cluster with 34 observations
cluster119_32 <- subset(words_with_cluster119,
subset=kmeans119 == 32)
View(cluster119_32)
# Health
# find out in which cluster the word health is assigned
words_with_cluster119[words_with_cluster119$word == "health", ]
# make a df of cluster 85
cluster119_85 <- subset(words_with_cluster119,
subset=kmeans119 == 85)
# Depression
# find out in which cluster the word depression is assigned
words_with_cluster119[words_with_cluster119$word == "depression", ]
# make a df of cluster 10
cluster119_10 <- subset(words_with_cluster119,
subset=kmeans119 == 10)
View(cluster119_10)
words_with_cluster119[words_with_cluster119$word == "depressed", ]
words_with_cluster119[words_with_cluster119$word == "depressive", ]
worcs::git_update()
